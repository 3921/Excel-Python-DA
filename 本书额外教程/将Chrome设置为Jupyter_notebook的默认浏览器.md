# 第八章:开始烹调-数据运算
进行到这一步的时候，就可以开始了正式的烹调了。第一章我们讲过数据分析到底在分析什么，列举了一些不同维度的分析指标，这一章我们就主要看看这些指标都是怎么计算出来的。

## 8.1算数运算  

算术运算就是基本的加减乘除，在Excel或Python中数值类型的任意两列可以直接进行加减乘除运算,而且是对应元素进行加减乘除运算，Excel中算数运算比较简单，这里就不展开了，下面主要讲一下Python中的算数运算。

两列相加
```
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6
>>>df["C1"] + df["C2"]
S1    3
S2    9
dtype: int64
```

两列相减
```
>>>df["C1"] - df["C2"]
S1   -1
S2   -1
dtype: int64
```

两列相乘
```
>>>df["C1"] * df["C2"]
S1     2
S2    20
dtype: int64
```

两列相除
```
>>>df["C1"] / df["C2"]
S1    0.5
S2    0.8
dtype: float64
```

任意一列加减一常数值，这一列中所有值都加减这一常数值。
```
>>>df["C1"] + 2
S1    3
S2    6
Name: C1, dtype: int64

>>>df["C1"] - 2
S1   -1
S2    2
Name: C1, dtype: int64
```
任意一列乘除一常数值，这一列中的所有值都乘除这一常数值。
```
>>>df["C1"] * 2
S1    2
S2    8
Name: C1, dtype: int64

>>>df["C1"] / 2
S1    0.5
S2    2.0
Name: C1, dtype: float64
```

## 8.2比较运算
比较运算符和Python基础知识中讲到的比较运算一致，也是常规的大于、等于、小于之类的，只不过这里的比较是在列与列之间的进行的。

|运算符|描述|示例|
|--|--|--|
|==|等于|(10 == 20)返回False|
|!=|不等于|(10 != 20)返回True|
|<>|不等于|(10 <> 20)返回True|
|>|大于|(10 > 20)返回False|
|<|小于|(10 < 20)返回True|
|>=|大于等于|(10 >= 20)返回False|
|<=|小于等于|(10 <= 20)返回True|

在Excel中列与列之间的比较运算和Python中是一致的。

![](https://ws1.sinaimg.cn/large/006JdmJily1fun9mzypavj30be0480sr.jpg)

下面是一些Python中列与列之间比较的例子。
```
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6

>>>df["C1"] > df["C2"]
S1    False
S2    False
dtype: bool

>>>df["C1"] != df["C2"]
S1    True
S2    True
dtype: bool

>>>df["C1"] != df["C2"]
S1    True
S2    True
dtype: bool
```
## 8.3汇总计算
上面讲到的算数运算和比较运算都是在列与列之间进行的，运算结果是有多少行就会返回多少个结果，而汇总运算是将数据进行汇总返回一个汇总以后的结果值。

### 8.3.1count非空值计数

非空值计数就是计算某一个区域中非空（单元格）数值的个数。

在Excel中counta()函数是用来计算某个区域中非空单元格个数。与counta()函数类似的一个函数是count()函数，counta()函数是用来计算某个区域中含有数字的单元格个数。

在Python中，直接在整个数据表上调用count()函数，返回的结果为该数据表中每列的非空值个数。

```
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6
>>>df.count()
C1    2
C2    2
C3    2
dtype: int64
```
count()函数默认是求取每一列上非空数值的个数，可以通过修改`axis`参数，让其等于1，来求取每一行的非空数值的个数。

```
>>>df.count(axis = 1)
S1    3
S2    3
dtype: int64
```

也可以把某一列或者某一行索引出来，单独查看这一列或这一行的非空值个数。
```
>>>df["C1"].count()
2
```

### 8.3.2sum求和

求和就是对某一区域中的所有数值进行加和操作。

在Excel中要求取某一区域的和，直接在sum()后面的括号中指明要求和的区域，即要对哪些值进行求和操作即可。

比如:
```
sum(D2:D6)#表示对D2:D6范围的数值进行求和操作
```

在Python中，直接在整个数据表上调用sum()函数，返回的是该数据表每一列的求和结果。

```
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6
>>>df.sum()
C1    5
C2    7
C3    9
dtype: int64
```
sum()函数同样也是默认对每一列进行求和，可通过修改`axis`参数，并让其等于1，来对每一行的数值进行求和操作。

```
>>>df.sum(axis = 1)
S1     6
S2    15
dtype: int64
```

也可以把某一列或者某一行索引出来，单独对这一列或这一行数据进行求和操作。

```
>>>df["C1"].sum()
5
```

### 8.3.3mean求均值

求均值是针对某一区域中的所有值进行求算数平均值运算。均值是用来数据一般情况的指标，容易受到极大值极小值的影响。

在Excel中要对某区域内的值进行求平均值运算，需要用到average()函数，只需要在average()括号中指明要求均值运算的区域即可。

比如：

```
average(D2:D6)#表示对D2:D6范围内的值进行求均值运算
```

在Python中的求均值利用的是mean()函数，如果对整个表直接调用mean()函数，返回的是该表中每一列的均值。

```
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6
>>>df.mean()
C1    2.5
C2    3.5
C3    4.5
dtype: float64
```

mean()函数默认是对数据表中的每一列进行求均值运算，可通过修改`axis`参数，并让其等于1，来对每一行进行求均值运算。

```
>>>df.mean(axis = 1)
S1    2.0
S2    5.0
dtype: float64
```
也可以把某一列或者某一行通过索引的方式取出来，然后在这一行或这一列上调用mean()函数，单独求取这一行或这一列
的均值。

```
>>>df["C1"].mean()#对C1列求均值
2.5
```

### 8.3.4max求最大值

求最大值就是比较一组数据中所有数值的大小，然后返回最大的一个值。

在Excel和Python中求最大值都是使用的max()函数，在Excel中同样只需要在max()的括号中指明要求最大值的区域即可；在Python中，和其他函数一样，如果整个表直接调用max()函数，返回该数据表中每一列的最大值，也可以对每一行求最大值，也可以单独对某一行或某一列求最大值。

```
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6
>>>df.max()
C1    4
C2    5
C3    6
dtype: int64
```

```
#对每一行求均值
>>>df.max(axis = 1)
S1    3
S2    6
dtype: int64
```

```
>>>df["C1"].max()#对C1列求均值
4
```

### 8.3.5min求最小值

求最小值与求最大值是相对应的，通过比较一组数据中所有数值大小，然后返回最小的那个值。

在Excel和Python中都是使用的min()函数，使用方法与求最大值，这里不再赘述。

```
#对整个表调用min()函数
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6
>>>df.min()
C1    1
C2    2
C3    3
dtype: int64
```

```
#求取每一行的最小值
>>>df.min(axis = 1)
S1    1
S2    4
dtype: int64
```

```
#求取C1列的最小值
>>>df["C1"].min()
1
```

### 8.3.6median求中位数

中位数就是将一组含有n个数据的序列X从小到大排列，位于中间位置的那个数。

中位数是以中间位置的数来反映数据的一般情况，不容易受到极大值极小值的影响，因而在反映数据分布情况上要比平均值更有代表性。

现有序列X：{X1、X2、X3、......、Xn}

如果N为奇数，则中位数：
```math
m = X_{\frac{n+1}{2}}
```

如果N为偶数，则中位数：
```math
m = \frac{X_{\frac{n}{2}}+X_{\frac{n}{2}+1}}{2}
```

```
1,3,5,7,9的中位数为5
```

```
1,3,5,7的中位数为(3+5)/2 = 4
```

在Excel和Python中求一组数据中的中位数，都是使用的median()函数。

下面为Excel中求中位数示例：

```
median(D2:D6)#表示求D2:D6区域内的中位数
```

在Python中，median()函数的使用原则和其他函数一致。

```
#对整个表调用median()函数
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6
S3  7   8   9
>>>df.median()
C1    4.0
C2    5.0
C3    6.0
dtype: float64
```

```
#求取每一行的中位数
>>>df.median(axis = 1)
S1    2.0
S2    5.0
S3    8.0
dtype: float64
```

```
#求取C1列的中位数
>>>df["C1"].median()
4.0
```

### 8.3.7mode求众数

众数顾名思义就是一组数据中出现次数最多的值，求众数就是返回这组数据中出现出现次数最多的那个值。

在Excel和Python中求取众数都是使用的mode()函数，使用原则与其他函数完全一致。

Excel求众数示例：

```
mode(D2:D6)#返回区域D2:D6之间出现次数最多的值
```
Python求众数：

```
#整个表调用mode()函数
>>>df
C1	C2	C3
S1	1	1   3
S2	4	4	6
S3	1	1	3
>>>df.mode()
	C1	C2	C3
0	1	1	3
```

```
#求取每一行的众数
>>>df.mode(axis = 1)
	0
S1	1
S2	4
S3	1
```

```
#求取C1列的众数
>>>df["C1"].mode()
0    1
dtype: int64
```

### 8.3.8var求方差
方差是用来衡量一组数据的离散程度的，即数据波动幅度。

在Excel和Python中求一组数据中的方差，都是使用的var()函数。

下面为Excel中求方差示例：

```
var(D2:D6)#表示求D2:D6区域内的方差
```

在Python中，var()函数的使用原则和其他函数一致。

```
#对整个表调用var()函数
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6
S3  7   8   9
>>>df.var()
C1    9.0
C2    9.0
C3    9.0
dtype: float64
```

```
#求取每一行的方差
>>>df.var(axis = 1)
S1    1.0
S2    1.0
S3    1.0
dtype: float64
```

```
#求取C1列的方差
>>>df["C1"].var()
9.0
```

### 8.3.9std求标准差
标准差是方差的平方根，都是用来表示数据的离散程度的。

在Excel中计算标准差使用的是STDEVP函数，如下：

```
STDEVP(D2:D6)#表示求D2:D6区域内的标准差
```
在Python中计算标准差使用的是std函数，std函数的使用原则与其他函数一致：

```
#对整个表调用std()函数
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6
S3  7   8   9
>>>df.std()
C1    3.0
C2    3.0
C3    3.0
dtype: float64
```

```
#求取每一行的标准差
>>>df.std(axis = 1)
S1    1.0
S2    1.0
S3    1.0
dtype: float64
```

```
#求取C1列的标准差
>>>df["C1"].var()
3.0
```

### 8.3.10quantile求分位数
分位数是是比中位数基于位置的更加详细的一个指标，主要有四分之一分位数、二分之一分位数、四分之三分位数，其实四分之二分位数就是中位数。

在Excel中求分位数用的是percentile函数，如下：
```
percentile(D2:D6,0.5)#表示求D2:D6区域内的二分之一分位数
percentile(D2:D6,0.25)#表示求D2:D6区域内的四分之一分位数
percentile(D2:D6,0.75)#表示求D2:D6区域内的四分之三分位数
```

在Python中求分为数用的是quantile函数，quantile函数与其他函数的使用规则相同：

```
#对整个表调用quantile()函数
>>>df
	C1	C2	C3
S1	1	2	3
S2	4	5	6
S3	7	8	9
S4	10	11	12
S5	13	14	15
>>>df.quantile(0.25)#求四分之一分位数
C1    4.0
C2    5.0
C3    6.0
Name: 0.5, dtype: float64
```

```
#求取每一行的四分之一分位数
>>>df.quantile(0.25，axis = 1)
S1     1.5
S2     4.5
S3     7.5
S4    10.5
S5    13.5
Name: 0.25, dtype: float64
```

```
#求取C1列的四分之分位数
>>>df["C1"].quantile(0.25)
4.0
```

## 8.4相关性计算 
相关性常用来衡量两个事物之间的相关程度，比如我们前面举的啤酒与尿布，就是二者的相关性很强。我们一般用相关系数来衡量两者相关程度，所以相关性计算其实也是计算相关系数，比较常用的皮尔逊相关系数。

在Excel中求取相关系数用的是correl函数，如下：

```
correl(A1:A10,B1:B10)#求取A列指标与B列指标的相关系数
```

在Python中求取相关系数用的是corr函数，实例如下：

```
>>>df
	col1	col2
0	1	    2
1	3	    4
2	5	    6
3	7	    8
4	9	    10
>>>df["col1"].corr(df["col2"])#求取col1列与col2列的相关系数
0.9999999999999999
```

# 第九章:炒菜计时器-时间序列
## 9.1获取当前时刻时间
获取当前时刻时间就是获取此时此刻的时间相关的数值，除了具体的年月日小时分秒以外，还会单独看年、月、周、日等指标。

### 9.1.1返回当前时刻的日期和时间

返回当前时刻的日期和时间Excel和Python实现都是借助于函数now。

Excel中直接在单元格中输入now函数即可，python中使用如下代码：

```
>>>from datetime import datetime
>>>datetime.now()
#2018年10月14日9时9分51秒
datetime.datetime(2018, 10, 14, 9, 9, 51, 539765)
```
### 9.1.1分别返回当前时刻的年、月、日

返回当前时刻的年份在Excel和Python实现都是借助于函数year。

在Excel中的单元格中输入如下函数：

```
=year(now())
```

在Python中使用如下代码：

```
>>>datetime.now().year
2018
```

返回当前时刻的月份在Excel和Python实现都是借助于函数month。

在Excel中的单元格中输入如下函数：

```
=month(now())
```

在Python中使用如下代码：

```
>>>datetime.now().month
10
```

返回当前时刻的日在Excel和Python实现都是借助于函数month。

在Excel中的单元格中输入如下函数：

```
=day(now())
```

在Python中使用如下代码：

```
>>>datetime.now().day
14
```

上面几个函数在其他任意日期时间中都适用。

### 9.1.2返回当前时刻的周数

当前时刻的周相关的数据有两个，一个是当前时刻是一周中的周几，另一个是返回当前时刻所在的周在全年的周里面算第几周。

**返回周几**

返回当前时刻是周几在Excel和Python都是借助于weekday函数。

在Excel中的单元格中输入如下函数：

```
weekday(now()-1)
```

之所以now()-1是因为Excel中的周日是作为一周中的第一天。

在Python中使用如下代码：

```
>>>datatime.now.weekeday()+1
7
```
python中周几是从0开始数的，周日返回的是6，所以在后面加1。

**返回周数**

返回当前时刻所在周的周数在Excel使用的是weeknum函数，在Python使用的是isocalendar函数。

在Excel中的单元格中输入如下函数：

```
weeknum(now()-1)
```

在Python中使用如下代码：

```
>>>datatime.now.isocalendar()
(2018, 41, 7)#2018年第41周的第7天
>>>datatime.now.isocalendar()[1]#返回周数
41
```
上面两个函数在其他任意日期时间中都适用。

## 9.2指定日期时间格式

**Excel实现**

在Excel中要设置日期时间格式，直接选中要设置的单元格，然后右键设置单元格格式即可。因为日期和时间是两个概念，所以在Excel中设置日期和时间是分开的。

![](https://ws1.sinaimg.cn/large/7602070dly1fw7i8ntpk5j20l80jk3zl.jpg)

**Python实现**

将日期时间设置成只展示日期部分,借助date函数：

```
#9小时9分51秒
>>>datetime.now.date()
datetime.date(2018, 10, 14)
```

将日期时间设置成只展示时间部分,借助time函数：

```
#9小时9分51秒
>>>datetime.now.time()
datetime.time( 9, 9, 51, 539765)
```

还可以自定义时间日期格式，借助strftime函数,strftime函数是将日期时间格式的时间转化为某些自定义的格式，具体的格式有以下：

|代码|说明|
|--|--|
|%H|小时(24小时制)[00,23]|
|%I|小时(12小时)[01,12]|
|%M|2位数的分[00,59]|
|%S|秒[00，61]|
|%w|用整数表示星期几，从0开始|
|%U|每年的第几周,周日被认为是每周第一天|
|%W|每年的第几周,周一被认为是每周第一天|
|%F|%Y-%m-%d的简写形式,例如2018-04-18|
|%D|%m/%d/%y的简写形式,例如04/18/2018|

```
>>>datetime.now().strftime('%Y-%m-%d')
'2018-10-14'

>>>datetime.now().strftime("%Y-%m-%d %H:%M:%S")
'2018-05-06 11:44:18'
```

## 9.3字符串和时间格式相互转换
字符串和时间格式的相互转换主要在Python中使用。
### 9.3.1将时间格式转换为字符串格式

将时间格式转换为字符串格式，使用的是str函数,如下：

```
#新建一个时间格式时间
>>>now = datetime.now()
>>>now
datetime.datetime(2018, 10, 14, 9, 9, 51, 539765)
>>>type(now)#查看变量now的数据类型
datetime.datetime
>>>type(str(now))
str
```
### 9.3.1将字符串格式转换为时间格式

将字符串格式转化为时间格式，使用的parse函数，如下：

```
#新建一个字符串格式的时间
>>>str_time = "2018-10-14"
>>>type(str_time)#查看变量str_time的数据类型
str
>>>from dateutil.parser import parse
>>>parse(str_now)#将字符串解析为时间
datetime.datetime(2018, 10, 14, 0, 0)
>>>type(parse(str_now))
datetime.datetime
```

## 9.4时间索引
时间索引就是对时间格式的字段根据时间来进行数据选取的一种索引方式。

**Excel实现**

在Excel中，对于时间格式的列有专门的日期筛选，根据需要选择相应的筛选条件即可，如下：

![](https://ws1.sinaimg.cn/large/7602070dly1fw7o6nl09pj20ew0hy3zk.jpg)

**Python实现**

在Python中，可以选取具体的某一时间对应的值，也可以选取某一段时间内的值。

新建一个时间索引的DataFrame:

```
>>>import pandas as pd
>>>import numpy as np
>>>index = pd.DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',
               '2018-01-09', '2018-01-10'])
>>>data = pd.DataFrame(np.arange(1,11),columns = ["num"],index = index)
>>>data
	        num
2018-01-01	1
2018-01-02	2
2018-01-03	3
2018-01-04	4
2018-01-05	5
2018-01-06	6
2018-01-07	7
2018-01-08	8
2018-01-09	9
2018-01-10	10
```

**获取2018年的数据**

```
>>>data["2018"]
	        num
2018-01-01	1
2018-01-02	2
2018-01-03	3
2018-01-04	4
2018-01-05	5
2018-01-06	6
2018-01-07	7
2018-01-08	8
2018-01-09	9
2018-01-10	10
```

**获取2018年1月的数据**

```
>>>data["2018-01"]
	        num
2018-01-01	1
2018-01-02	2
2018-01-03	3
2018-01-04	4
2018-01-05	5
2018-01-06	6
2018-01-07	7
2018-01-08	8
2018-01-09	9
2018-01-10	10
```

**获取1月1号到5号的数据**

```
>>>data["2018-01-01":"2018-01-05"]
	        num
2018-01-01	1
2018-01-02	2
2018-01-03	3
2018-01-04	4
2018-01-05	5
```

**获取1月1号的数据**

```
>>>data["2018-01-01":"2018-01-01"]
	        num
2018-01-01	1
```

上面的索引方法适用于索引是时间的情况下，但是并不是所有的情况下，时间都可以做索引，比如一个订单表中订单ID是索引，成交时间就是一个普通列，这个时候你想选取某一段时间内的成交订单该怎么取呢？

因为时间也是有大小关系的，我们可以利用前面学过的索引方式中的布尔索引来对非索引列的时间进行选取，如下：

```
>>>df
	客户姓名 唯一识别码	年龄	成交时间
A1	张通	 101	    31	    2018-08-08
A2	李谷	 102	    45	    2018-08-09
A3	孙凤	 103	    23	    2018-08-10
A4	赵恒	 104	    36	    2018-08-11
A5	王娜	 105	    21	    2018-08-11

#选取成交时间为8月8日的订单
>>>df[df["成交时间"] == datetime(2018,8,8)]
	客户姓名 唯一识别码	年龄	成交时间
A1	张通	 101	    31	    2018-08-08

#选取成交时间在8月9日之后的订单
>>>df[df["成交时间"] > datetime(2018,8,9)]
	客户姓名 唯一识别码	年龄	成交时间
A3	孙凤	 103	    23	    2018-08-10
A4	赵恒	 104	    36	    2018-08-11
A5	王娜	 105	    21	    2018-08-11

#选取成交时间在8月10日之前的订单
>>>df[df["成交时间"] < datetime(2018,8,10)]
	客户姓名 唯一识别码	年龄	成交时间
A1	张通	 101	    31	    2018-08-08
A2	李谷	 102	    45	    2018-08-09

选取成交时间在8月8与8月11之间的订单
>>>df[(df["成交时间"] > datetime(2018,8,8))&(df["成交时间"] < datetime(2018,8,11))]
	客户姓名 唯一识别码	年龄	成交时间
A2	李谷	 102	    45	    2018-08-09
A3	孙凤	 103	    23	    2018-08-10
```

## 9.5时间运算

### 9.5.1两时间之差

在日常业务中经常会用到计算两个时间的差，比如要计算一个用户在某平台上的生命周期，则拿用户最后一次登陆产品的时间去减用户首次登陆产品的时间即可。

**Excel实现**

在Excel中两日期直接做差会得到一个带小数点的天数，如果你只想看两日期之间差多少天，那么直接取整数部分就可以，如果想看两日期之间差多少小时、分钟，则需要对小数点部分进行计算，取小数点部分乘24的结果中的整数部分就是小时数，小数部分乘60就是分钟数。

```
date_A = 2018/5/18 20:32
date_B = 2018/5/21 19:50
date_B - date_A = 2.970833
day = 2
hour = int(0.970833*24) = int(23.299992) = 23
minute = int(0.299992*60) = int(17.99952) = 17
```

**Python实现**

在Python中两时间做差会返回一个timmedelta对象，该对象中包含天数、秒、微秒三个等级，如果要获取小时、分钟，则需要对秒进行换算。

```
>>>cha = datetime(2018,5,21,19,50) - datetime(2018,5,18,20,32)
>>>cha
#差值为2天83880秒
datetime.timedelta(2, 83880)
>>>cha.days#返回天时间差
2
>>>cha.seconds#返回秒时间差
83880
>>>cha.seconds/3600#换算成小时差
23.3
```

### 9.5.2时间偏移

时间偏移是指给时间往前推或往后推一段时间，即加或减一段时间。

**Excel实现**

在Excel中若想对一时间具体加减某一单位的时间，运算单位都是天，如果是加减小时或者分钟，则需要把小时或分钟换算成对应的天。

```
#往后推1天
date1 = 2018/5/18 20:32 + 1 = 2018/5/19 20:32

#往后推3小时
date2 = 2018/5/18 20:32 + 0.125 = 2018/5/19 23:32

#往后推60分钟
date3 = 2018/5/18 20:32 + 0.041666667 = 2018/5/19 21:32

#往前推1天
date4 = 2018/5/18 20:32 - 1 = 2018/5/17 20:32

#往前推3小时
date5 = 2018/5/18 20:32 - 0.125 = 2018/5/19 17:32

#往后推60分钟
date6 = 2018/5/18 20:32 - 0.041666667 = 2018/5/19 19:32
```

**Python实现**

在Python中实现时间偏移有两种方式，第一种是借助timedelta,只能偏移天、秒、微秒单位的时间；第二种是pandas中的日期偏移量(date offset)。

**timedelta**

timedelta只支持天、秒、微秒维度的时间运算，如果是其他为维度的时间运算，则需要换算成上面三种维度方可进行偏移。

```
>>>from datetime import timedelta
>>>date = datetime(2018,5,18,20,32)
#往后推1天
>>>data + timedelta(days = 1)
datetime.datetime(2018,5,19,20,32)

#往后推60秒
>>>data + timedelta(seconds = 60)
datetime.datetime(2018,5,18,20,33)

#往前推1天
>>>data - timedelta(days = 1)
datetime.datetime(2018,5,17,20,32)

#往前推60秒
>>>data - timedelta(seconds = 60)
datetime.datetime(2018, 5, 18, 20, 31)
```

**date offset**

date offset直接天、小时、分钟维度时间偏移，不需要换算，相比timedelta要方便一些。

```
>>>from pd.tseries.offsets import Day,Hour,Minute
>>>date = datetime(2018,5,18,20,32)

#往后推1天
>>>date + Day(1)
Timestamp('2018-05-19 20:32:00')

#往后推1小时
>>>date + Hour(1)
Timestamp('2018-05-18 21:32:00')

#往后推10分钟
>>>date + Minute(1)
Timestamp('2018-05-18 20:42:00')

#往前推1天
>>>date - Day(1)
Timestamp('2018-05-17 20:32:00')

#往前推1小时
>>>date + Hour(1)
Timestamp('2018-05-18 19:32:00')

#往前推10分钟
>>>date + Minute(1)
Timestamp('2018-05-18 20:22:00')
```

# 第十章:凉菜热菜分类-数据透视表/数据分组
## 10.1数据分组

数据分组就是根据一个或多个键(可以是函数、数组或df列名)将数据分成若干组，然后对分组后的数据分别进行汇总计算，并将汇总计算后的结果进行合并，被用作汇总计算的函数称为聚合函数。具体分组流程如下：

![](https://ws1.sinaimg.cn/large/006JdmJily1futbc32405j30gd08zaan.jpg)

先讲一下在Excel中数据分组是如何实现的，然后在详细讲Python又是如何实现的。

**Excel实现**

Excel中有数据分组这个功能，但是在使用这个功能以前需要先对键进行排序(你要按照哪一列进行分组，那么键就是这一列数值)，升序降序都可以。

![](https://ws1.sinaimg.cn/large/006JdmJily1futbnl8seuj30ba06lq30.jpg)

对键值排序好以后，选中待分组区域，然后依次点击菜单栏中的数据>数据分组就可以。分类字段、汇总方式都可以根据需求自己选择。汇总方式就是对分组后的数据进行什么样的运算，我们这里是进行的计数运算。

![](https://ws1.sinaimg.cn/large/006JdmJily1futbs07k1cj30hw0bwdi1.jpg)

Excel中常见的汇总方式主要有如下几种：

|汇总方式|含义|
|-----|-----|
|求和|对分组后的数据进行求和|
|计数|对分组后的数据进行计数|
|平均值|对分组后的数据求平均值|
|最大值|返回分组后数据的最大值|
|最小值|返回分组后数据的最小值|
|乘积|对分组后的数据相乘|
|偏差|求分组后数据的偏差|
|方差|求分组后数据的方差|


**Python实现**

在Python中对数据分组利用的groupby()方法，这个有点类似于sql中groupby，在接下来的几个小节里面，我们重点介绍Python中的groupby()方法。

### 10.1.1分组键是列名

分组键是列名，直接将某一列或多列列名传给groupby()，groupby()就会按照这一列或这多列进行分组。

**按照一列进行分组**

```
>>>df
	用户ID	客户分类	区域	  是否省会  7月销量	8月销量	9月销量
0	59224	A类	    一线城市	  是	    6	    20	    0
1	55295	B类	    三线城市	  否	    37	    27	    35
2	46035	A类	    二线城市	  是	    8	    1	    8
3	2459	C类	    一线城市	  是	    7	    8	    14
4	22179	B类	    三线城市	  否	    9	    12  	4
>>>df.groupby("客户分类")
<pandas.core.groupby.DataFrameGroupBy object at 0x000001FBB43F4908>
```

从上面结果可以看出，如果只是传入列名，运行groupby()以后返回的不是一个DataFrame对象，而是一个DataFrameGroupBy对象，这个对象里面包含着分组以后的若干组数据，需要对这些分组数据进行汇总计算以后才会展示出来。

```
>>>df.groupby("客户分类").count()

        用户ID	区域	是否省会	7月销量	8月销量	9月销量
客户分类						
A类	    3	    3	    3	    3	    3	    3
B类	    2	    2	    2	    2	    2	    2
C类	    1	    1	    1	    1	    1	    1
```

上面的代码是根据客户分类对所有数据进行分组，然后对分组以后的数据分别进行计数运算，最后再进行合并。

上面是对分组后的数据进行计数运算，所以每一列都会有一个结果，但是如果对数据做一些数值运算，这个时候就只有数据类型是数值(int、float)的列才会参与运算，比如下面的求和运算。

```
>>>df.groupby("客户分类").sum()
	    用户ID	7月销量	8月销量	9月销量
客户分类				
A类	    127816	 56	    41	    63
B类	    77474	 46	    39	    39
C类	    2459	 7	    8	    14
```

章节8.3讲过的汇总运算都可以作为groupby分组后数据的聚合函数。

**按照多列进行分组**

上面分组键是某一列，即按照一列进行分组，也可以按照多列进行分组，只需要将多个列名以列表的形式传给groupby即可，汇总计算方式与按照单列进行分组以后数据运算方式一致。

```
#对分组后的数据进行计数运算
>>>df.groupby(["客户分类","区域"]).count()
		     用户ID	是否省会	7月销量	8月销量	9月销量
客户分类	区域					
A类	一线城市	 1	    1	     1	    1	    1
    二线城市	 2	    2	     2	    2	    2
B类	三线城市	 2	    2	     2	    2	    2
C类	一线城市	 1 	    1	     1	    1	    1
```

```
#对分组后的数据进行求和运算
>>>df.groupby(["客户分类","区域"]).sum()
		         用户ID	7月销量	8月销量	9月销量
客户分类	区域				
A类	    一线城市	 59224	 6	    20	    0
        二线城市	 68592	 50	    21	    63
B类	    三线城市	 77474	 46	    39	    39
C类	    一线城市	 2459	 7	    8	    14
```

**对分组以后的某些列进行汇总计算**

不管是分组键是一列还是多列，如果直接在分组后的数据上进行汇总计算，是对所有可以进行计算的列进行计算，有的时候我们不需要对所有列进行计算，这个时候就可以把想要计算的列（可以是单列，也可以是多列）通过索引的方式取出来，然后再在取出来这列数据的基础上进行汇总计算。

比如我们想看一下A、B、C类客户分别有多少，我们先按照客户分类进行分组，然后把用户ID这一列取出来，在这一列的基础上进行计数汇总计算即可。

```
>>>df.groupby("客户分类")["用户ID"].count()
客户分类
A类    3
B类    2
C类    1
Name: 用户ID, dtype: int64
```

### 10.1.2分组键是Series

把DataFrame的其中一列取出来就是一个Series，比如下面的df["客户分类"]就是一个Series。

```
>>>df["客户分类"]
0    A类
1    B类
2    A类
3    C类
4    B类
5    A类
Name: 客户分类, dtype: object
```

分组键是列名与分组键是Series的唯一区别就是给groupby()传入什么，其他都一样。可以按照一个或多个Series进行分组，分组以后的汇总计算也是完全一样的，也支持对分组以后的某些列进行汇总计算。

**按照一个Series进行分组**

```
#对分组以后的数据进行计数运算
>>>df.groupby(df["客户分类"]).count()
	    用户ID	区域	是否省会	7月销量	8月销量	9月销量
客户分类						
A类	    3	    3	    3	    3	    3	    3
B类	    2	    2	    2	    2	    2	    2
C类	    1	    1	    1	    1	    1	    1
```

**按照多个Series进行分组**

```
#对分组以后的数据进行求和运算
>>>df.groupby([df["客户分类"],df["区域"]]).sum()
		         用户ID	7月销量	8月销量	9月销量
客户分类	区域				
A类	    一线城市	 59224	 6	    20	    0
        二线城市	 68592	 50	    21	    63
B类	    三线城市	 77474	 46	    39	    39
C类	    一线城市	 2459	 7 	    8 	    14
```

**对分组以后的某些列进行汇总计算**

```
>>>df.groupby(df["客户分类"])["用户ID"].count()
客户分类
A类    3
B类    2
C类    1
Name: 用户ID, dtype: int64
```

### 10.1.3神奇的aggregate方法

前面用到的聚合函数都是直接在DataFrameGroupBy上调用的，这样分组以后所有列都是做的同一种汇总运算，且一次只能使用一种汇总方式。

aggregate的第一个神奇之处在于一次可以使用多种汇总方式,比如下面的例子，先对分组后的所有列做计数汇总运算，然后再对所有列做求和汇总运算。
```
>>>df
	用户ID	客户分类	7月销量	8月销量
0	59224	A类	    6	    20
1	55295	B类	    37	    27
2	46035	A类	    8	    1
3	2459	C类	    7	    8
4	22179	B类	    9	    12
>>>df.group("客户分类").aggregate(["count","sum"])
	    用户ID	       7月销量	     8月销量
        count  sum	   count	sum	 count	sum
客户分类						
A类	    3	   127816  3	    56	 3	    41
B类	    2	   77474   2	    46	 2	    39
C类	    1	   2459	   1        7	 1	    8
```

aggregate的第二个神奇之处在于可以针对不同的列做不同的汇总运算,比如下面的例子，我们想看不同类别的用户有多少，那么对用户ID进行计数，我们想看不同类别用户7、8月销量，需要对销量进行求和。
```
>>>df.groupby("客户分类").aggregate({"用户ID":"count","7月销量":"sum","8月销量":"sum"})

        用户ID	7月销量	8月销量
客户分类			
A类	    3	    56	    41
B类	    2	    46	    39
C类	    1	    7	    8
```

### 10.1.4对分组后的结果重置索引
通过上面代码的运行结果可以看到，DataFrameGroupBy对象经过汇总运算以后的形式并不是标准的DataFrame形式。为了接下来对分组结果进行进一步处理与分析，我们需要把非标准形式转化为标准的DataFrame形式，利用的方法就是重置索引reset_index()方法。
```
>>>df.group("客户分类").sum()
        用户ID	 7月销量	   8月销量
客户分类			
A类	    127816	 56	       41
B类	    77474	 46	       39
C类	    2459	 7	       8
>>>df.group("客户分类").sum().reset_index()
	客户分类   用户ID	7月销量	  8月销量
0	A类	      127816	56	      41
1	B类	      77474	    46	      39
2	C类	      2459	    7   	  8
```

## 10.2数据透视表

数据透视表实现的功能与数据分组相类似但又不同，数据分组是在一维(行)方向上不断进行拆分，而数据透视表是在行列方向上同时进行拆分。

下图为数据分组与数据透视表的对比图：

![](https://ws1.sinaimg.cn/large/006JdmJily1fuvf0sw8qcj30tf0ep0th.jpg)

数据透视表不管是在Excel还是Python中都是一个很重要的功能，大家都需要熟练掌握。

**Excel实现**

Excel中的数据透视表在插入菜单栏中，选择插入透视表以后就会看到下图的界面。下图左侧为数据表中的所有字段，右侧为数据透视表选项，把左侧字段拖到右侧对应的框中即完成了数据透视表的制作。

![](https://ws1.sinaimg.cn/large/006JdmJily1fuvf6i1dafj30hs0c8q51.jpg)

下图为让客户分类作为行标签，区域作为列标签，用户ID作为值，且值字段的计算类型为计数的结果。

![](https://ws1.sinaimg.cn/large/006JdmJily1fuvf84m0r9j30c703xwek.jpg)

在数据透视表中把多个字段作拖到行对应的框作为行标签，把多个字段拖到列对应的框作为列标签，把多个字段拖到值对应的框作为值，且可以对不同的值字段选择不同的计算类型，大家自行练习。

**Python实现**

在Python中的数据透视表制作原理与Excel制作原理是一样的。Python中的数据透视表用到的是pivot_table()方法。

pivot_table的全部参数如下：
```
pd.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean',
                   fill_value=None, margins=False, dropna=True, margins_name='All')
                   
#data表示要做数据透视表的整个表
#values对应Excel中值那个框
#index对应Excel中行那个框
#columns对应Excel中列那个框
#aggfunc表示对values的计算类型
#fill_value表示对空值的填充值
#margins表示是否显示合计列
#dropna表示是否删除缺失,一整行全为缺失值
#margins_name表示合计列列名
```

接下来看一些具体实例：

客户分类作为index，区域作为columns，用户ID作为values，对values执行count运算运行结果：
```
>>>pd.pivot_table(df,values = "用户ID",columns = "区域",index = "客户分类",aggfunc='count')
区域	一线城市  三线城市	二线城市
客户分类			
A类	    1.0       NaN	    2.0
B类	    NaN	      2.0	    NaN
C类	    1.0	      NaN	    NaN
```

上面的运行结果和Excel的不同的就是没有合计列，Python透视表中的合计列默认是关闭，让其等于True就可以显示出来。
```
>>>pd.pivot_table(df,values = "用户ID",columns = "区域",index = "客户分类",aggfunc='count',margins = True)
区域	一线城市  三线城市	二线城市  All
客户分类				
A类	    1.0	      NaN	    2.0	      3
B类	    NaN	      2.0	    NaN	      2
C类	    1.0 	  NaN	    NaN	      1
All	    2.0	      2.0	    2.0	      6
``` 

合计列名称默认为All，可以通过设置参数margins_name的值进行修改。

```
>>>pd.pivot_table(df,values = "用户ID",columns = "区域",index = "客户分类",aggfunc='count',margins = True,margins_name = "总计")
区域	一线城市  三线城市	二线城市  总计
客户分类				
A类	    1.0	      NaN	    2.0	      3
B类	    NaN	      2.0	    NaN	      2
C类	    1.0 	  NaN	    NaN	      1
总计	2.0	      2.0	    2.0	      6
``` 

NaN表示缺失值，我们可以通过设置参数fill_value的值对缺失值进行填充。

```
#将缺失值填充为0
>>>pd.pivot_table(df,values = "用户ID",columns = "区域",index = "客户分类",aggfunc='count',margins = True,fill_value = 0)
区域	一线城市  三线城市	二线城市  All
客户分类				
A类	    1         0   	    2	      3
B类 	0   	  2     	0	      2
C类	    1   	  0     	0      	  1
All	    2   	  2     	2	      6
``` 

aggfunc用来表示计算类型，当只传入一种类型时，表示对所有的值字段都进行同样的计算；如果需要对不同的值进行不同的计算类型，需要传入一个字典，键为列名，值为计算方式,下面对用户ID进行计数、对7月销量进行求和：

```
>>>pd.pivot_table(df,values = ["用户ID","7月销量"],,columns = "区域",index = "客户分类",aggfunc={"用户ID":"count","7月销量":"sum"})
     7月销量	                    用户ID
区域 一线城市 三线城市 二线城市	一线城市 三线城市	二线城市
客户分类						
A类	 6.0	  NaN	   50.0	    1.0	     NaN	    2.0
B类	 NaN      46.0 	   NaN	    NaN	     2.0	    NaN
C类	 7.0	  NaN	   NaN	    1.0	     NaN	    NaN
```

为了便于进一步的分析与处理，我们一般对数据透视表的结果也会重置索引，利用的方法同样是reset_index()。

```
>>>pd.pivot_table(df,values = "用户ID",columns = "区域",index = "客户分类",aggfunc='count')
区域	一线城市  三线城市	二线城市
客户分类			
A类	    1.0       NaN	    2.0
B类	    NaN	      2.0	    NaN
C类	    1.0	      NaN	    NaN
>>>pd.pivot_table(df,values = "用户ID",columns = "区域",index = "客户分类",aggfunc='count').reset_index()
区域	客户分类	    一线城市	    三线城市	    二线城市
0	    A类	        1.0     	NaN	        2.0
1   	B类     	NaN	        2.0     	NaN
2	    C类	        1.0	        NaN	        NaN
```

# 第十一章:水果拼盘-多表拼接
## 11.1表的横向拼接
表的横向拼接就是在横向将两个表依据公共列拼接在一起。

在Excel中实现横向拼接利用的就是vlookup()函数，关于vlookup()函数这里就不展开了，相加大家应该都很熟悉。

在Python中实现横向拼接利用的merge()方法，接下里的几个小节就主要围绕merge()方法进行展开。
### 11.1.1连接表类型

连接表类型就是待连接的两个表都是什么类型，主要有3中情况：一对一、多对一、多对多。

**一对一**

一对一就是待连接的两个表的公共列是一对一的，看下面这个例子。

```
>>>df1
    名次  姓名	学号  成绩
0	1	  小张	100	  650
1	2	  小王	101	  600
2	3	  小李	102	  578
3	4	  小赵	103	  550
>>>df2
    学号  班级
0	100	  一班
1	101	  一班
2	102	  二班
3	103	  三班
```
如果要将df1和df2这两个表进行连接，直接使用pd.merge()方法即可，该方法会自动寻找两个表中的公共列，并将寻找到的公共列作为连接列，上面例子中表df1和df2的公共列为学号，且学号是一对一的，两个表运行pd.merge()以后结果如下：

```
>>>pd.merge(df1,df2)

    名次  姓名	学号  成绩	班级
0	1	  小张	100	  650	一班
1	2	  小王	101	  600	一班
2	3 	  小李	102	  578	二班
3	4     小赵	103	  550	三班
```

**多对一**

多对一就是待连接两个表的公共列不是一对一的，其中有一个表的公共列是有重复值，另一个表的公共列是唯一的。

现在有一份名单df1中记录了每位学生升入高三以后的第一次模拟考试成绩，还有另一份名单df2记录了学号以及之后的每次模拟考试成绩，现在如果要将这两个表按照学号进行连接，这两个表就是多对一的关系，df1中的学号是唯一的，但是df2中学号不是唯一的，最后拼接结果就是保留df2中的重复值，且在df1中也增加重复值，实现代码如下：

```
>>>df1
	姓名	学号	f_成绩
0	小张	100	    650
1	小王	101	    600
2	小李	102	    578
>>>df2
	学号	e_成绩
0	100	    586
1	100	    602
2	101	    691
3	101	    702
4	102	    645
5	102	    676
>>>pd.merge(df1,df2,on = "学号")
	姓名	学号	f_成绩	e_成绩
0	小张	100 	650	    586
1	小张	100	    650 	602
2	小王	101	    600 	691
3	小王	101	    600	    702
4	小李	102	    578	    645
5	小李	102	    578 	676
```

**多对多**

多对多就是待连接的两个表的公共列不是一对一的，且两个表中的公共列都有重复值，看下面这个例子：

### 11.1.2连接键类型

**默认公共列**

如果事先没有指定要按哪个列进行拼接时，pd.merge()会默认寻找两个表中的公共列，然后以这个公共列作为连接键进行连接,比如下面这个例子，默认以公共列学号作为连接键：

```
>>>df1
    名次  姓名	学号  成绩
0	1	  小张	100	  650
1	2	  小王	101	  600
2	3	  小李	102	  578
3	4	  小赵	103	  550
>>>df2
    学号  班级
0	100	  一班
1	101	  一班
2	102	  二班
3	103	  三班
>>>pd.merge(df1,df2)

    名次  姓名	学号  成绩	班级
0	1	  小张	100	  650	一班
1	2	  小王	101	  600	一班
2	3 	  小李	102	  578	二班
3	4     小赵	103	  550	三班
```

**on用来指定连接键**

也可以用参数on来指定连接键，参数on一般指定的也是两个表中的公共列，其实这个时候和使用默认公共列达到的效果是一样的。

```
>>>pd.merge(df1,df2,on = "学号")

    名次  姓名	学号  成绩	班级
0	1	  小张	100	  650	一班
1	2	  小王	101	  600	一班
2	3 	  小李	102	  578	二班
3	4     小赵	103	  550	三班
```

公共列可以有多列，也就是连接键可以有多个，比如下面这个例子用学号和姓名两列做连接键：

```
>>>df1

    名次	姓名	学号	成绩
0	1	    小张	100 	650
1	2	    小王	101 	600
2	3   	小李	102	    578
3	4	    小赵	103 	550
>>>df2

    姓名	学号	班级
0	小张	100	    一班
1	小王	101	    一班
2	小李	102	    二班
3	小赵	103	    三班
>>>pd.merge(df1,df2,on = ["姓名","学号"])
	名次	姓名	学号	成绩	班级
0	1	    小张	100	    650	    一班
1	2	    小王	101	    600	    一班
2	3	    小李	102	    578	    二班
3	4	    小赵	103	    550	    三班
```

**分别指定左右连接键**

当两个表中没有公共列时，这里的列指列名不同，但实际值是一样的，要不然就没法连接了，这个时候就需要分别指定左表和右表的连接键，使用的参数是left_on和rigth_on，left_on用来指明左表用作连接的列名，right_on用来指明右表用作连接的列名，如下例子：

```
>>>df1
    名次  姓名	编号  成绩
0	1	  小张	100	  650
1	2	  小王	101	  600
2	3	  小李	102	  578
3	4	  小赵	103	  550
>>>df2
    学号  班级
0	100	  一班
1	101	  一班
2	102	  二班
3	103	  三班
>>>pd.merge(df1,df2,left_on = "编号",right_on = "学号")

	名次  姓名	成绩  编号	学号  班级
0	1	  小张	650	  100	100	  一班
1	2	  小王	600	  101	101	  一班
2	3	  小李	578	  102	102	  二班
3	4	  小赵	550	  103	103	  三班
```

**索引列当作连接键**

索引列不算做真正的列，当公共列是索引列时，这个时候就需要把索引列打开，让他当作连接键，使用的参数left_index和right_index，left_index用来控制左表的索引，right_index用来控制右表的索引，如下例子左右表的连接键均为各自索引：

```
>>>df1
	名次	姓名	成绩
编号			
100	1	    小张	650
101	2	    小王	600
102	3	    小李	578
103	4	    小赵	550
>>>df2

    班级
学号	
100	一班
101	一班
102	二班
103	三班
>>>pd.merge(df1,df2,left_index = True,right_index = True)
	名次	姓名	成绩	班级
编号				
100	1	    小张	650	    一班
101	2	    小王	600	    一班
102	3	    小李	578	    二班
103	4	    小赵	550	    三班
```

上面的例子是左表和右表的连接键均为索引，还可以是索引列和普通列混用，如下左表的连接键为索引，右表的连接键为普通列：

```
>>>df1
	名次	姓名	成绩
编号			
100	1	    小张	650
101	2	    小王	600
102	3	    小李	578
103	4	    小赵	550
>>>df2
	学号	班级
0	100	    一班
1	101	    一班
2	102	    二班
3	103	    三班
>>>pd.merge(df1,df2,left_index = True,right_on = "学号")
    名次	姓名	成绩	学号	班级
0	1	    小张	650	    100	    一班
1	2	    小王	600	    101	    一班
2	3	    小李	578	    102 	二班
3	4   	小赵	550 	103	    三班
```

### 11.1.3连接方式

上面我们举的例子比较标准，也就是左表中的公共列的值都可以在右表对应的公共列中找到，右表的公共列的值也是可以在左表中找到的，但是现实业务中很多是互相找不到的，这个时候该怎么办呢？这就衍生出了几种连接方式用来处理这种找不到的情况，用参数how来指明具体的连接方式。

**内连接(inner)**

内连接就是取两个表中的公共部分,下面例子中，学号100、101、102是两个表中公共部分，内连接以后就只有这三个学号对应的内容：

```
>>>df1
	名次	姓名	学号	成绩
0	1	    小张	100	    650
1	2	    小王	101 	600
2	3	    小李	102	    578
3	4	    小赵	103	    550
>>>df2
	姓名	学号	班级
0	小张	100	    一班
1	小王	101	    一班
2	小李	102 	二班
3	小钱	104	    三班
>>>pd.merge(df1,df2,on = "学号",how = "inner")
    名次 姓名_x	 学号  成绩	 姓名_y	 班级
0	1	 小张	 100   650	 小张    一班
1	2	 小王	 101   600	 小王	 一班
2	3	 小李	 102   578	 小李	 二班
```

如果不指明连接方式，默认都是内连接。

**左连接(left)**

左连接就是以左表为基础，右表往左表上拼接。如下例子，右表中没有学号为103的信息，拼接过来的信息就用NaN填充：

```
>>>pd.merge(df1,df2,on = "学号",how = "left")
    名次 姓名_x	 学号  成绩	 姓名_y	 班级
0	1	 小张	 100   650	 小张    一班
1	2	 小王	 101   600	 小王	 一班
2	3	 小李	 102   578	 小李	 二班
3	4	 小赵	 103   550	 NaN	 NaN
```

**右连接(right)**

右连接就是以右表为基础，左表往右表上拼接。如下例子，左表中没有学号为104的信息，拼接过来的信息就用NaN填充：

```
>>>pd.merge(df1,df2,on = "学号",how = "right")
    名次 姓名_x	 学号  成绩	 姓名_y	 班级
0	1	 小张	 100   650	 小张    一班
1	2	 小王	 101   600	 小王	 一班
2	3	 小李	 102   578	 小李	 二班
3	NaN	 NaN	 104   NaN	 小钱	 三班
```

**外连接(outer)**

外连接就是取两个表的并集。如下例子，左表中学号为100、101、102、103，右表中学号为100、101、102、104，外连接取并集以后的结果中应包含学号为100、101、102、103、104的信息：

```
>>>pd.merge(df1,df2,on = "学号",how = "outer")
	名次	姓名_x	学号	成绩	姓名_y	班级
0	1.0	    小张	100	    650.0	小张	一班
1	2.0	    小王	101	    600.0	小王	一班
2	3.0	    小李	102	    578.0	小李	二班
3	4.0	    小赵	103	    550.0	NaN	    NaN
4	NaN	    NaN	    104	    NaN	    小钱	三班
```

### 11.1.4重复列名处理

两个表在进行连接时，经常会遇到两个表中的列名重复的情况，在遇到列名重复时，pd.merge()会自动给这些重复列名添加后缀_x或_y或_z，而且会根据表中已有的列名自行调整，比如下面这个例子中的姓名列：

```
>>>df1
	名次	姓名	学号	成绩
0	1	    小张	100	    650
1	2	    小王	101 	600
2	3	    小李	102	    578
3	4	    小赵	103	    550
>>>df2
	姓名	学号	班级
0	小张	100	    一班
1	小王	101	    一班
2	小李	102 	二班
3	小钱	104	    三班
>>>pd.merge(df1,df2,on = "学号",how = "inner")
    名次 姓名_x	 学号  成绩	 姓名_y	 班级
0	1	 小张	 100   650	 小张    一班
1	2	 小王	 101   600	 小王	 一班
2	3	 小李	 102   578	 小李	 二班
```

当然我们也可以自定义重复的列名，只需要修改参数suffixes的值即可，默认为["_x","_y"]。

```
#给重复的列名加后缀_L和_R
>>>pd.merge(df1,df2,on = "学号",how = "inner",suffixes = ["_L","_R"])
    名次 姓名_L	 学号  成绩	 姓名_R	 班级
0	1	 小张	 100   650	 小张    一班
1	2	 小王	 101   600	 小王	 一班
2	3	 小李	 102   578	 小李	 二班
```


## 11.2表的纵向拼接

表的纵向拼接是与横向拼接相对应的，横向拼接是两个表依据公共列在水平方向上进行拼接，而纵向拼接是在垂直方向进行拼接。

一般的应用场景就是将分离的若干个表结构相同的数据表合并成一个数据表，比如在下面这个例子中，分别来自两个班的学生花名册，这两个表的结构是一样的，需要把这两个表进行合并：


在Excel中要实现这两个表的合并，只需要把表二复制粘贴到表一的下方即可。

在Python中我们要想实现在纵向合并上述两个表，需要用到concat()方法。

### 11.2.1普通合并

普通合并就是直接将要合并表的表名以列表的形式传给pd.concat()后面的括号中，运行代码，即可完成合并，如下例子：

```
>>>df1
	姓名	班级
编号		
1	许丹	一班
2	李旭文	一班
3	程成	一班
4	赵涛	一班

>>>df2
	姓名	班级
编号		
1	赵义	二班
2	李鹏	二班
3	卫来	二班
4	葛颜	二班
>>>pd.concat([df1,df2])
	姓名	班级
编号		
1	许丹	一班
2	李旭文	一班
3	程成	一班
4	赵涛	一班
1	赵义	二班
2	李鹏	二班
3	卫来	二班
4	葛颜	二班
```
这样就把一班的花名册和二班的花名册合并到了一起。

### 11.2.2索引设置

大家有没有觉得上面的索引列编号的具体数值看着有点不太顺眼，12341234，这是因为pd.concat()默认会保留原表的索引，而表df1的索引为1234，表df2的索引也为1234，合并后的索引固然是12341234，但是这样看着很不顺眼。

我们可以通过设置参数ignore_index的值，让其等于True，这样就会不保留原表的索引，而会生成一组新的索引，如下：
```
>>>pd.concat([df1,df2],ignore_index = True)
	姓名	班级
0	许丹	一班
1	李旭文	一班
2	程成	一班
3	赵涛	一班
4	赵义	二班
5	李鹏	二班
6	卫来	二班
7	葛颜	二班
```

### 11.2.3重叠数据合并

前面的数据都是比较干净的数据，现实情况中难免会有一些错误数据，比如一班的花名册里面把二班的人写进去了，而这个人在二班的花名册里面也是存在的，这个时候如何直接合并两个表的话，肯定是会有重复值的，那么该怎么处理呢？

我们先直接concat一下，看是什么结果：

```
>>>df1
	姓名	班级
编号		
1	许丹	一班
2	李旭文	一班
3	程成	一班
4	赵涛	一班
5	葛颜	二班
>>>df2
	姓名	班级
编号		
1	赵义	二班
2	李鹏	二班
3	卫来	二班
4	葛颜	二班
>>>pd.concat([df1,df2],ignore_index = True)
	姓名	班级
0	许丹	一班
1	李旭文	一班
2	程成	一班
3	赵涛	一班
4	葛颜	二班
5	赵义	二班
6	李鹏	二班
7	卫来	二班
8	葛颜	二班
```

看上面的结果中葛颜出现了两次，我们回想前面讲过的重复值处理，是不是可以处理这种情况呢，来看一下：

```
>>>pd.concat([df1,df2],ignore_index = True).drop_duplicates()
	姓名	班级
0	许丹	一班
1	李旭文	一班
2	程成	一班
3	赵涛	一班
4	葛颜	二班
5	赵义	二班
6	李鹏	二班
7	卫来	二班
```

经过删除重复值以后，葛颜就只出现了一次。

# 第十二章:成菜装盘-结果导出
## 12.1导出为xlsx文件
在Excel中要将文件保存为xlsx格式的文件，直接将文件另存为，在另存为时选择Excel工作薄(*.xlsx)格式即可，如下图所示：

![](https://ws1.sinaimg.cn/large/006JdmJily1fux4u6qjqfj30ob0fpta8.jpg)

如果是将文件导出的话只有PDF/XPS两种格式可选，如下图所示：

![](https://ws1.sinaimg.cn/large/006JdmJily1fux4xjman2j30o00avgm6.jpg)

在Python中将文件导出为xlsx格式，用到的df.to_excel()方法，接下来的几个小节具体讲解to_excel()方法。

### 12.1.1设置文件导出路径

设置文件导出路径就是告诉Python你要将这个文件导出到你电脑的哪个文件夹，且导出以后这个文件叫什么。只需要通过调整参数excel_writer的值即可：
```
>>>df.to_excel(excel_writer = r"C:\Users\zhangjunhong\Desktop\测试文档.xlsx")
```
上面代码表示将df这个表导出到桌面，且导出以后的文件为测试文档.xlsx，下图为导出以后的结果文档：

![](https://ws1.sinaimg.cn/large/006JdmJily1fux58a93j1j30ht04qaaj.jpg)

需要注意的是，如果同一导出文件已经在本地打开，则不能再次运行导出代码，会报错，需要将本地文件关闭以后再词运行导出代码。这个有点类似于我们在本地修改文件名的操作，如果文件是打开的，即被占用的状态，那么修改文档的操作是不可以执行的。

```
DataFrame.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None)  
```
### 12.1.2设置Sheet名称
我们知道xlsx格式的文件是有多个Sheet的，每个Sheet名字默认都是从Sheet1往上递增，当然我们也可以对默认的Sheet名字进行修改，只需要修改sheet_name参数即可。

```
>>>df.to_excel(excel_writer = r"C:\Users\zhangjunhong\Desktop\测试文档.xlsx",
sheet_name = "测试文档")
```

运行上面代码以后，导出到本地文件的sheet名字将从原来的Sheet1变成测试文档。

### 12.1.3设置索引
上面导出文件中关于索引的参数都是默认的，也就是没有对索引做什么限制，但是我们可以看到index索引使用的是从0开始的默认自然数索引，这种索引是没有意义的，我们可以在导出的时候把这种索引去掉，只需要让参数index=False即可：
```
>>>df.to_excel(excel_writer = r"C:\Users\zhangjunhong\Desktop\导出文档.xlsx",
             sheet_name = "测试文档",
             index = False)
```
上面代码运行结果如下，从0开始的自然数索引没有被展示出来。

![](https://ws1.sinaimg.cn/large/006JdmJily1fux5ms19sxj30fm05cwez.jpg)

### 12.1.4设置要导出的列
有的时候一个表中的列数很多，我们并不需要把所有的列都导出，这个时候就可以通过设置columns参数来指定你要导出的列，和导入的时候设置只导入部分列的原理是类似的，代码如下：

```
>>>df.to_excel(excel_writer = r"C:\Users\zhangjunhong\Desktop\导出文档.xlsx",
             sheet_name = "测试文档",
             index = False,
             columns = ["用户ID","7月销量","8月销量","9月销量"])
```
下表为只导出用户ID、7月销量、8月销量、9月销量的结果文件：

![](https://ws1.sinaimg.cn/large/006JdmJily1fux7bovh4oj308z05f0sq.jpg)

### 12.1.5设置编码格式
我们在导入文件时需要设置编码格式，导出文件的时候同样也需要，修改编码格式的参数与导入文件时一致，也是使用的encoding，encoding参数值一般选择"utf-8"。
```
>>>df.to_excel(excel_writer = r"C:\Users\zhangjunhong\Desktop\导出文档.xlsx",
             sheet_name = "测试文档",
             index = False,
             encoding = "utf-8"
             )
```
### 12.1.6缺失值处理
虽然我们在前面的数据预处理过程中已经把缺失值处理掉了，但是在数据分析过程中也可能会产生一些缺失值，如果在导出的时候，数据表中有缺失值，那么就需要对表中的缺失值进行填充，使用的参数为na_rep。

```
>>>df.to_excel(excel_writer = r"C:\Users\zhangjunhong\Desktop\导出文档.xlsx",
             sheet_name = "测试文档",
             index = False,
             encoding = "utf-8",
             na_rep = 0#缺失值填充为0
             )
```

### 12.1.7无穷值处理
无穷值inf是与缺失值Nan相对应的一种异常数据，当你用一个浮点数去除0时，就会得到一个无穷值inf,无穷值的存在会导致接下来的计算报错，所以需要对无穷值进行处理。

可以通过下面这种方式生成正无穷与负无穷值：
```
>>>float("inf")
inf
>>>float("-inf)
-inf
```

下面的数据表中含有inf值，要把这个inf值替换掉，需要设置参数inf_rep的值。

![](https://ws1.sinaimg.cn/large/006JdmJily1fux6axsa99j30gf07hwf1.jpg)

```
>>>df.to_excel(excel_writer = r"C:\Users\zhangjunhong\Desktop\导出文档.xlsx",
             sheet_name = "测试文档",
             index = False,
             encoding = "utf-8",
             na_rep = 0,#缺失值填充为0
             inf_rep = 0#无穷值填充为0             
)
```
下表为导出到本地的文档，可以看到inf值已经被替换成0了。

![](https://ws1.sinaimg.cn/large/006JdmJily1fux69i3eavj30fn04smxm.jpg)

## 12.2导出为csv文件
DataFrame.to_csv(path_or_buf=None, sep=', ', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='"', line_terminator='\n', chunksize=None, tupleize_cols=None, date_format=None, doublequote=True, escapechar=None, decimal='.')

在Excel中要将文件保存为csv格式的文件，直接将文件另存为，在另存为时有两种csv文件可选，这两种虽然后缀均为csv,但是编码方式不同，CSV UTF-8(逗号分割)采用的编码格式是UTF-8，而CSV(逗号分割)采用的gbk编码，如下图所示：

![](https://ws1.sinaimg.cn/large/006JdmJily1fux7swmieyj30o70fq75t.jpg)

在Python中，将文件导出为csv文件使用的to_csv方法，接下来的几个小节具体讲解to_csv方法的一些参数。

### 12.2.1设置文件导出路径

设置csv文件的导出路径时，与xlsx文件的导出意思一样，但是参数不一样，csv文件的导出路径需通过path_or_buf参数来设置。

```
>>>df.to_csv(path_or_buf = r"C:\Users\zhangjunhong\Desktop\导出文档.csv")
```
导出csv文件时的注意事项与导出xlsx文件注意事项一致：如果同一导出文件已经在本地打开，则不能再次运行导出代码，会报错，需要将本地文件关闭以后再词运行导出代码。

### 12.2.2设置索引
导出csv时与导出xlsx文件时对索引的设置是一致的，可以通过设置index参数，让从0开始的默认自然数索引不展示出来:
```
>>>df.to_csv(path_or_buf = r"C:\Users\zhangjunhong\Desktop\导出文档.csv",
             index = False)
```
### 12.2.3设置要导出的列
导出csv文件时也可以设置要导出哪些列，用的参数同样是columns：
```
>>>df.to_csv(path_or_buf = r"C:\Users\zhangjunhong\Desktop\导出文档.csv",
             index = False,
             columns = ["用户ID","7月销量","8月销量","9月销量"])
```
### 12.2.4设置分隔符

分隔符就是用来指明你导出文件中的字符之间是用什么来分隔的，默认是使用的逗号分隔，常用的还有空格、制表符、分号之类。用参数sep来指明你要用的分隔符。
```
>>>df.to_csv(path_or_buf = r"C:\Users\zhangjunhong\Desktop\导出文档.csv",
             index = False,
             columns = ["用户ID","7月销量","8月销量","9月销量"])
             sep = ","
```

### 12.2.5缺失值处理
导出csv文件时的缺失值处理与导出xlsx文件时用的缺失值处理方法是一样的，也是通过参数na_rep来指明你要用什么填充缺失值。

```
>>>df.to_csv(path_or_buf = r"C:\Users\zhangjunhong\Desktop\导出文档.csv",
             index = False,
             columns = ["用户ID","7月销量","8月销量","9月销量"],)
             sep = ",",
             na_rep = 0
```
### 12.2.6编码设置
在Python3中，导出为csv文件时，文件默认编码为utf-8,而utf-8都是可以在我们本地电脑正常打开的，所以一般使用默认编码格式即可。
```
>>>df.to_csv(path_or_buf = r"C:\Users\zhangjunhong\Desktop\导出文档.csv",
             index = False,
             columns = ["用户ID","7月销量","8月销量","9月销量"],)
             sep = ",",
             na_rep = 0,
             encoding = "utf-8"
```


## 12.3将文件导出到多个Sheet

有的时候一个脚本里一次会生成多个文件，可以将这多个文件分别导出成多个文件，也可以将这多个文件放在一个文件的不同sheet中，这个时候需要用ExcelWriter()函数，这多个文件需要分别导出到不同sheet中，具体方法如下：

```
#声明一个读写对象
#excelpath为文件要存放的路径
writer = pd.ExcelWriter(excelpath,engine = "xlsxwriter")

#分别将表df1、df2、df3写入到excel中的sheet1、sheet2、sheet3
#并命名为表1、表2、表3
df1.to_excel(writer,sheet_name = "表1")
df2.to_excel(writer,sheet_name = "表2")
df3.to_excel(writer,sheet_name = "表3")

#保存读写的内容
writer.save()
```

# 第十三章:菜品摆放-数据可视化
## 13.1数据可视化是什么

现在假设你要向你们老板汇报你们公司1-9月的注册人数，下面三种是不同的表现形式，你会选择哪种表现形式，如果你是老板，你希望收到下属发来那种形式的汇报呢？

![](https://ws1.sinaimg.cn/large/006JdmJily1fuyzuj3szjj30sw09d3zt.jpg)

我相信大部分人对这三者的选择顺序应该是图>表>字，即所谓的字不如表，表不如图。之所以会优先选择图的形式，是因为图不仅可以看出每个月具体的数值，而且还可以看出趋势以及最值点。

我们把这种借助图形来清晰有效表达信息的方式称为可视化，可视化可以帮助我们更好地去传递信息。

## 13.2数据可视化基本流程

### 13.2.1整理数据
数据可视化的基础还是数据，你要将数据图表化，首先需要整理数据，明确要把哪些数据图表化。

比如我们要把最近几个月的销量数据图表化。

### 13.2.2明确目的

知道了要把哪些数据图表化以后，就需要明确目的，我们前面说了，可视化是用来表达信息的一种方式，既然是用来表达信息的，就应该是明确我们要表达什么，要传递给看图这个人什么信息。

比如说我是要表达最近几个月的销量呈上涨的趋势，还是要表达我们的用户中有超过50%的用户是90后群体。

### 13.2.3寻找合适的表现形式

明确了你要表达什么信息以后，就可以去选择合适的表现形式，不同的目的使用的表现形式也是不一样的。

还是拿我们前面的例子，你要说明最近几个月的销量趋势，肯定是首选折线图，通过折线图的走势，可以很清楚看出最近几个月销量是上升还是下降的；如果你要说明不同年龄层用户的占比，首选肯定是饼图，这样很清楚就能看出哪个年龄层占比最大，哪个占比最小。

## 13.3图表基本组成元素

下图为一个正规的可视化图表，该表包含了一个图表中的基本组成元素：

![](https://ws1.sinaimg.cn/large/006JdmJily1fuz2ak2zn2j30o60chaas.jpg)

**画布**

画布就是字面意思，你首先需要找到一块布，即绘图界面，然后在这一块布上去绘制图表。

**坐标系**

画布是图表的最大概念，在一块画布上可以建立多个坐标系，坐标系又可以分为直角坐标系、球坐标系和极坐标系三种，其中直角坐标系最常用。


**坐标轴**

坐标轴是在坐标系中的概念，主要有x和y轴(一般简单的可视化均为二维)，一组x/y值用来唯一确定坐标系上的一个点。

x轴也称横轴就是我们上图中的月份，y轴也称纵轴就是我们上图中的注册人数。

在这个坐标系中，月份和注册人数唯一确定一个点。

**坐标轴标题**

坐标轴标题就是x轴和y轴的名称，上图中我们把x轴叫做月份，y轴叫做注册人数。

**图表标题**

图表标题是用来说明整个图表核心主题的，上图中的核心主题就是1-9月中每月的注册人数。

**数据标签**

数据标签就是将图表中的数值展示出来，上图为折线图，是由不同月份和注册人数唯一确定不同的点，然后将这些点连接起来就是一个折线图，折线图是一条线，如果将每个拐点处对应的数值显示出来，这些数值就是数据标签。

**数据表**

数据表就是在图表下方以表格的形式将图表中x和y值展示出来。

**网格线**

网格线是坐标轴的延升，通过网格线可以更加清晰便捷地看到每一点大概在什么什么位置，值大概等于多少。

**图例**

图例一般位于图表的下方或右方，用来说明不同的符号或颜色来代表不同的内容与指标，有助于更好的认清地图。

上图中我们只有一条折线，所以图例的作用不是很大，但是当一个图表中有多条折线图，或者不同形状的混合，这个时候图例的作用就显而易见了。你可以很快分出哪个颜色的折线代表哪个指标。

**误差线**

误差线主要用来显示显示坐标轴的每个点的不确定程度，一般用标准差表示，即一个点的误差为该点的实际值加减标准差。

## 13.4Excel与Python可视化
前面讲的数据可视化的基本流程以及图表的基本组成元素不管是用Excel还是Python都是一样的。

在Excel进行数据可视化比较简单，直接选中要图表化的数据，然后点击插入图表，再选择合适的图表类型，选择好图表以后就可以对图表格式进行设置。

![插入图表](https://ws1.sinaimg.cn/large/7602070dly1fw6twy6omjj20p9073js4.jpg)

![图表格式设置](https://ws1.sinaimg.cn/large/7602070dly1fw6tzhfimuj20tz0d5jtc.jpg)

因为Excel图表绘制相对比较简单，所以本书就不再赘述，接下来的部分主要讲解Python中的图表格式设置以及常用图表绘制。

## 13.5画布以及坐标轴建立
### 13.5.1画布建立
在开始正式的画布建立之前，我们需要先把要用到的库给加载进来，在Python中我们可视化用的库是matplotlib库。除了导入matplotlib库以外还需要另外多加三行代码，这样图表才能正常显示，具体代码如下：

```
#导入matplotlib库中的pyplot并起别名为plt
>>>import matplotlib.pyplot as plt

#让图表直接在jupyter_notebook中展示出来
>>>%matplotlib inline

#解决中文乱码问题
>>>plt.rcParams["font.sans-serif"]='SimHei'

#解决负号无法正常显示的问题
>>>plt.rcParams['axes.unicode_minus'] = False
```

>默认设置下matplotlib做出来的图表不是很清晰，这个时候可以将图表设置成矢量图格式显示，看起来就会很清晰，只需要在上面代码块中加一行代码：%config InlineBackend.figure_format = 'svg'。

我们需要的库导进来以后就可以正式开始建立画布了，具体如下：

```
>>>fig = plt.figure()
<matplotlib.figure.Figure at 0x1d5a0384208>
```

plt.figure里面有一个参数figsize，以(width, height)的形式用来控制整块画布的宽和高。

```
#建立宽为8高为6的画布
>>>plt.figure(figsize = (8,6))
<matplotlib.figure.Figure at 0x256823bbcc0>
```

>需要注意的一点就是建立画布以后画布并不会直接显示出来，只会输出一串画布相关信息的代码。

画布建立好以后就可以在画布上绘制坐标系了，在Excel中直接选择插入图表就相当于建立一个坐标系，在Python中会有多种建立坐标系的方式，接下来具体看一下这几种不同的建立方式。

### 13.5.2add_subplot建立坐标系
利用add_subplot函数建立坐标系时需要先有画布，再在画布上绘制坐标系的。

```
>>>fig = plt.figure()
>>>ax1 = fig.add_subplot(1,1,1)
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6cc0kgsoj23vc2kwkao.jpg)

上面代码表示在画布fig上绘制1*1个坐标系，并且把第一个坐标系赋值给变量ax1。

```
>>>fig = plt.figure()
>>>ax1 = fig.add_subplot(2,2,1)
>>>ax2 = fig.add_subplot(2,2,2)
>>>ax3 = fig.add_subplot(2,2,3)
>>>ax4 = fig.add_subplot(2,2,4)
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw6cdhn63aj23vc2kw1kx.jpg)

上面代码表示在画布fig上同时绘制2*2个坐标，即4个坐标系，并且把第一个坐标系赋值给变量ax1；第二个坐标系赋值给ax2；第三个坐标系赋值给ax3；第四个坐标系赋值给ax4。

### 13.5.3plt.subplot2grid建立坐标系
用plt.subplot2grid函数建立坐标系时不需要先建立画布，只需要导入plt库，即pyplot即可。导入plt以后可以直接调用plt库的subplot2grid方法进行坐标轴建立,示例如下：

```
>>>plt.subplot2grid((2,2),(0,0))
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6ch2a6dpj23vc2kw1au.jpg)


上面代码表示将图表的整个区域被分成2行2列，且在(0，0)位置作图。

用这种方式建立坐标系时，具体的绘图代码需要跟在建立坐标系语句后面。


```
>>>import numpy as np
>>>x = np.arange(6)
>>>y = np.arange(6)

#将图表的整个区域分成2行2列，且在(0，0)位置作折线图
>>>plt.subplot2grid((2,2),(0,0))
>>>plt.plot(x,y)

#将图表的整个区域分成2行2列，且在(0，1)位置作柱状图图
>>>plt.subplot2grid((2,2),(0,1))
>>>plt.bar(x,y)
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw013za9igj23vc2kwtel.jpg)

### 13.5.4plt.subplot建立坐标系
plt.subplot与plt.subplot2grid类似，也是plt的一个函数，也表示将区域分成几份，并指明在哪一块区域上绘图，两者的区别就是表示形式不一样。

```
>>>plt.subplot(2,2,1)
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw0fzlxzzej23vc2kw0ye.jpg)

上面代码表示将图表的整个区域被分成2行2列，且在第一个坐标系里面绘图。

用这种方式建立坐标系时同样需要将具体的绘图代码跟在建立坐标系语句后面。

```
>>>import numpy as np
>>>x = np.arange(6)
>>>y = np.arange(6)

#将图表的整个区域分成2行2列，且在第一个坐标系中作折线图
>>>plt.subplot(2,2,1)
>>>plt.plot(x,y)

#表示将图表的整个区域分成2行2列，且在第4个坐标轴系作柱状图
>>>plt.subplot(2,2,4)
>>>plt.bar(x,y)
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw0g2d8scdj23vc2kw0yu.jpg)

### 13.5.5plt.subplots建立坐标系

plt.subplots也是plt库的一个函数，但是与上面的subplot2grid和subplot不同，不同之处是前面介绍的两种建立坐标系的方式每次只返回一个坐标系，而subplots一次可以返回多个坐标轴。

```
>>>fig,axes = plt.subplots(2,2)
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw00h1xcpij23vc2kw1kx.jpg)

上面代码也表示将整个区域分成2行2列，并将4个坐标系全部返回。你想在哪个坐标系里面绘图通过axes[x,y]进行指明即可。

```
>>>import numpy as np
>>>x = np.arange(6)
>>>y = np.arange(6)

#在[0,1]坐标系中绘制折线图
>>>axes[0,1].plot(x,y)

#在[1.0]坐标系中绘制柱状图
>>>axes[1,1].bar(x,y)
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw0g5l7hxzj23vc2kw12h.jpg)

### 13.5.6几种创建坐标系的区别

第一种创建坐标系的方法add_subplot属于对象编程，所有的操作都是针对某个对象进行的，比如先建立一块画布，然后在这块画布上去建立坐标系进而在坐标系上进行绘图。而后三种建立坐标系的方法属于函数编程，都是直接调用plt库里面的某个函数或者方法达到创建坐标系的目的。

对象式编程代码比较繁琐，但是便于理解；函数式编程虽然代码简洁，但是不利于新人去掌握整体的绘图原理，所以建议大家刚开始的时候多使用对象式编程，当大家对整个绘图原理很熟悉时，再去尝试使用函数式编程。

这两种编程方式不仅体现在创建坐标系中，在接下来的一些操作中也会有涉及，有的时候两者会交叉使用，也就是在一个代码中既有函数式编程，也由对象式编程。

## 13.6坐标轴设置
### 13.6.1坐标轴标题设置
坐标轴标题就是x/y轴分别叫什么名字，下图中x轴为具体月份，y轴为注册量，设置方法为：

```
>>>plt.xlabel("月份")
>>>plt.ylabel("注册量")
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw0g8ahwxej23vc2kw7gp.jpg)

还可以设置x/ylabel距离x/y轴的距离，给参数labelpad传入具体的距离数即可，如下：

```
>>>plt.xlabel("月份",labelpad = 10)
>>>plt.ylabel("注册量",labelpad = 10)
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw0gaz9b93j23vc2kw7gp.jpg)

还可以对x/ylabel的文本相关性质进行设置，比如设置字体大小、字体颜色、是否加粗等，如下为了增加区分度，只对xlable的文本进行了设置：

```
>>>plt.xlabel("月份",fontsize='xx-large',color = "#70AD47",fontweight = 'bold')
>>>plt.ylabel("注册人数")
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw0gxc1ehbj23vc2kwgy8.jpg)

### 13.6.2坐标轴刻度设置
坐标轴刻度设置的第一点就是x/y轴每个刻度处显示什么，默认都是显示x/y值，可以自定义显示不同刻度处的值,使用的方法是是plt库中的x/yticks函数：

```
#ticks表示刻度值，labels表示该刻度处对应的标签
plt.xticks(ticks,labels)
plt.yticks(ticks,labels)
```

x/yticks中的labels也支持文本相关设置，与x/ylabel中文本设置方式一致。

下图中x轴的刻度值均自定义成某月份，y轴的刻度值均定义成多少人：

```
#设置x轴刻度
>>>plt.xticks(np.arange(9),["1月份","2月份","3月份",
            "4月份","5月份","6月份","7月份","8月份","9月份"])
#设置y轴刻度
>>>plt.yticks(np.arange(1000,7000,1000),
            ["1000人","2000人","3000人","4000人","5000人","6000人"])
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw0h1ybiejj23vc2kwdtt.jpg)

有的时候为了数据安全不会把x/y轴的数值具体显示出来，这个时候只需要给xticks/yticks传入一个空列表就会把x/y轴的数值给隐藏掉：

```
>>>plt.xticks([])
>>>plt.yticks([])
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw0h35u00hj23vc2kwk0t.jpg)

除了x/yticks方法以外，还可以使用plt库中tick_params函数对轴刻度线进行设置。

```
plt.tick_params(axis,reset,which,direction,length,width,color,pad,labelsize,labelcolor,bottom, top, left, right,labelbottom, labeltop, labelleft, labelright,)
```
|参数|说明|
|--|--|
|axis|对哪个轴的刻度线进行设置，x、y、both三个可选|
|reset|是否重置所有设置，True/False|
|which|对哪种刻度线进行设置，major(主刻度线)、minor(次刻度线)、both(全部)三个可选|
|direction|刻度线的朝向，in(朝里)、out(朝外)、inout(里外均有)三个可选|
|legth|刻度线长度|
|width|刻度线长度|
|color|刻度线颜色|
|pad|刻度线与刻度标签之间的距离|
|labelsize|刻度标签大小|
|labelcolor|刻度标签颜色|
|bottom, top, left, right|True/False可选，控制上下左右刻度线是否显示|
|labelbottom, labeltop, labelleft, labelright|True/False可选，控制上下左右刻度标签是否显示|

```
x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])
y = array([ 866, 2335, 5710, 6482, 6120, 1605, 3813, 4428, 4631])

#在2*1个坐标系中的第一个坐标系中作图
>>>plt.subplot(2,1,1)
>>>plt.plot(x,y)
>>>plt.xlabel("月份")
>>>plt.ylabel("注册人数")

#轴刻度线设置成双向且下轴刻度线不显示
>>>plt.tick_params(axis = "both",which = "both",direction = "inout",bottom = "false")

#在2*1个坐标系中的第二个坐标系中作图
>>>plt.subplot(2,1,2)
>>>plt.plot(x,y)
>>>plt.xlabel("月份")
>>>plt.ylabel("注册人数")

#轴刻度线设置成双向且下轴刻度标签不显示
>>>plt.tick_params(axis = "both",which = "both",direction = "inout",labelbottom = "false")

```

![](https://ws1.sinaimg.cn/large/7602070dly1fw0ibih8laj23nd2qj7su.jpg)

### 13.6.3坐标轴范围设置
坐标轴刻度范围就是设置坐标轴的最大值和最小值，下图中x轴的刻度范围设置为0-10，y轴的刻度范围设置为0-8000：

```
>>>plt.xlim(0,10)
>>>plt.ylim(0,8000)
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw0ivhu1m5j23vc2kwqdx.jpg)

### 13.6.4坐标轴轴显示设置
有的时候为了美观，会把一些不必要的轴给关闭，就是不让显示出来，这个时候就可以通过坐标轴的轴显示设置达到目的，坐标轴中的轴默认都是显示出来的，可以通过如下方式进行关闭：

```
>>>plt.axis("off")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw0iwrawd6j23vc2kwwln.jpg)

## 13.7其他图表格式设置
### 13.7.1网格线设置

网格线是相比于坐标轴更小的一个单位，网格线默认是关闭的，可以通过修改参数b的值，让等于True来启用网格线：

```
>>>plt.grid(b = "True")
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw6cvslwe5j23vc2kw4qp.jpg)

让参数b = True，默认是将x/y轴的网格线全部打开，可以通过修改参数axis的值进而控制要打开哪个轴的网格线：

```
>>>plt.grid(b = "True",axis = "x")#只打开x轴的网格线
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw6cww6lujj23vc2kw1kx.jpg)

```
>>>plt.grid(b = "True",axis = "y")#只打开y轴的网格线
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6cwx5xacj23vc2kw1kx.jpg)

网格线也属于线，所以除了可以设置显示x/y轴以外，还可以对网格线的线本身进行设置，比如线宽、线型、线的颜色等,关于线相关的设置会在折线图绘制部分详细讲解。

```
#线型设置成虚线，线宽设置成1
>>>plt.grid(b = "True",linestyle='dashed', linewidth=1)
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6d21cpydj23vc2kw4qp.jpg)

### 13.7.2图例设置

图例是对图表起到注释的作用，在绘图的时候通过给label参数值传入值表示该图表的图例名，最后通过plt.legend()将图例显示出来，使用方法有如下：

```
>>>plt.plot(x,y,label = "折线图")
>>>plt.bar(x,y,label = "柱状图")
>>>plt.legend()
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6d94adelj23vc2kw1kx.jpg)

还可以通过修改loc参数的参数值来调整图例的显示位置，loc参数值如下：

|字符串|位置代码|说明|
|--|--|--|
|"best"|0|根据图表区域自动选择最合适的展示位置|
|"upper right"|1|图例显示在右上角|
|"upper left"|2|图例显示在左上角|
|"lower left"|3|图例显示在左下角|
|"lower right"|4|图例显示在右下角|
|"right"|5|图例显示在右侧|
|"center left"|6|图例显示在左侧中心位置|
|"center right"|7|图例显示在右侧中心位置|
|"lower center"|8|图例显示在底部中心位置|
|"upper center"|9|图例显示在顶部中心位置|
|"center"|10|图例显示在正中心位置|

在具体设置图例位置时，可以给参数loc传入字符串也可以传入位置代码,下面两行代码表达的意思是一样的，都是让图例显示在左上角位置：

```
>>>plt.legend(loc = "upper left")
>>>plt.legend(loc = 2)
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6dart3zzj23vc2kw1kx.jpg)

图例的显示默认都是1列，可以通过参数ncol设置成多列，如下：

```
>>>plt.plot(x,y,label = "折线图")
>>>plt.bar(x,y,label = "柱状图")
>>>plt.legend(ncol = 2)
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6d8feegmj23vc2kw1kx.jpg)

除了上面几个常用参数外，还有如下参数可以设置：

|参数|说明|
|--|--|
|fontsize|图例字体大小|
|prop|关于文本相关设置，以字典形式传给参数prop|
|facecolor|图例框的背景颜色|
|edgecolor|图例框的边框颜色|
|title|图例标题|
|title_fontsize|图例标题大小|
|shadow|是否给图例框添加阴影，默认为False|

### 13.7.3图表标题设置

图表的标题是用来说明整个图表的核心思想的，主要通过如下方式给图表起标题：

```
>>>plt.title(s = "1-9月XXX公司注册用户数")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6dnh71l0j23vc2kwqur.jpg)

还可以通过修改参数loc的值来修改标题的显示位置，默认都是居中显示的，loc参数值有三个可选：

|字符串|说明|
|--|--|
|center|居中显示|
|left|靠左显示|
|right|靠右显示|

```
#图表标题靠左显示
>>>plt.title(s = "1-9月XXX公司注册用户数",loc = "left")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6dni7qowj23vc2kwnoy.jpg)

还可以通过fontdict参数对标题文字相关性质进行设置。

### 13.7.4数据标签设置
数据标签实现就是根据x/y的坐标值在对应位置显示相应的数值，实现方法如下：

```
plt.text(x,y,str,fontdict)
```
|参数|说明|
|--|--|
|参数(x,y)|分别表示要在哪里显示数值|
|str|表示要显示的具体数值|
|horizontalalignment|简称ha,表示str在水平方向的位置，有center、left、right三个值可选|
|verticalalignment|简称va,表示str在垂直方向的位置，有center、top、bottom三个值可选|
|fontsize|str字体大小设置|

```
#在(5,1605)处显示该点的y值
>>>plt.text(5,1605,"极值点")
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw6g5alef7j23vc2kw7we.jpg)

plt.text函数只是针对坐标轴中的具体某一点(x,y)显示数值str，要想对整个图表显示数据标签，就需要利用for进行遍历，实例如下：

```
#在(x,y)处显示y值
>>>for a,b in zip(x,y):
    plt.text(a,b,b,ha ='center', va ="bottom",fontsize=11))
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6e6qcg5rj23vc2kw4qp.jpg)

### 13.7.5图表注释
图表注释与数据标签的作用类似，都是便于看图者更快地理解图表信息，实现方法如下：

```
plt.annotate(s,xy,xytext,arrowprops)
```
|参数|说明|
|--|--|
|s|表示要注释的文本内容|
|xy|表示要注释的位置|
|xytext|表示要注释的文本的显示位置|
|arrowprops|箭相关参数设置，颜色、箭类型设置|

```
>>>plt.annotate("服务器宕机了",xy = (5,1605),xytext = (6,1605),arrowprops=dict(facecolor='black',arrowstyle = '->'))
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6gdaso3hj23vc2kw1kx.jpg)

facecolor表示箭的颜色，arrowstyle表示箭的类型，主要有如下几种：
|类型|
|--|
|'-'|	
|'->'|
|'-['|
|'|-|'|
|'-|>'|
|'<-'|
|'<->'|
|'<|-|>'|
|'fancy'|
|'simple'|
|'wedge'|

### 13.7.6数据表
数据表就是在图表基础上再添加一个表格，使用的是plt库中的table函数。

```
table(cellText=None,cellColours=None,
      cellLoc='right',colWidths=None,
      rowLabels=None, rowColours=None, rowLoc='left',
      colLabels=None, colColours=None, colLoc='center',
      loc='bottom')
```
|参数|说明|
|--|--|
|cellText|数据表内的值|
|cellColours|数据表的颜色|
|cellLoc|数据表中数值的的位置，left、right、center可选|
|colWidths|列宽|
|rowLabels|行标签|
|rowColours|行标签颜色|
|rowLoc|行标签位置|
|colLabels|列标签|
|colColours|列标签颜色|
|colLoc|列标签位置|
|loc|整个数据表的位置，坐标系的上下左右可选|

实例如下：

```
>>>cellText = [[ 8566, 5335, 7310, 6482],
               [4283,2667,3655,3241]]
>>>rows = ["任务量","完成量"]
>>>columns = ["东区","南区","西区","北区"]
>>>plt.table(cellText = cellText,cellLoc='center',
             rowLabels=rows,rowColours = ["red","yellow"],rowLoc = "center",
             colLabels=columns,colColours = ["red","yellow","red","yellow"],colLoc='left',
             loc='bottom')
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6w6pf7bxj23vc2kwb29.jpg)

## 13.8常用图表绘制
### 13.8.1折线图绘制

折线图常用于表示随着时间的推移某指标的变化趋势情况，使用的是plt库中的plot方法。


**参数详解**

具体参数如下：

```
plt.plot(x,y,color,line_style,line_width,marker,markeredgecolor,markeredgwidth,markerfacecolor,markersize,label)
```

参数x,y分别表示x/y轴的的数据；
color表示折线图的颜色，主要有如下参数值可选：

|代码|颜色|
|--|--|
|"b"|蓝色|
|"g"|绿色|
|"r"|红色|
|"c"|青色|
|"m"|品红|
|"y"|黄色|
|"k"|黑色|
|"w"|白色|

上面的颜色参数值是颜色缩写代码，color参数值除了用颜色缩写代码以外，还可以用标准颜色名称、十六进制颜色值、RGB元组，比如黑色用不同方式表示如下：

|表示方式|具体值|
|--|--|
|颜色缩写代码|k|
|标准颜色名称|black|
|十六进制|#000000|
|RGB元组|0,0,0|

这些颜色参数值在其他图表中也通用。

line_style表示线的风格，主要有如下参数值可选：

|代码|线形|
|--|--|
|solid|实线(-)|
|dashed|短线(--)|
|dashdot|短点相接(-.)|
|dotted|虚点线|

line_width表示线的宽度，传入一个表示宽度的浮点数即可；

marker表示折线图中每点的标记物形状，主要有如下参数值可选：


|代码|说明|
|--|--|
|'.'|点标记|
|'o'|圆圈标记|
|'v'|下三角形标记|
|'^'|上三角形标记|
|'<'|左三角形标记|
|'>'|右三角形标记|
|'s'|正方形标记|
|'p'|五边形标记|
|'*'|五角星标记|
|'h'|六边形标记|
|'+'|+号标记|
|'x'|x标记|
|'D'|大菱形标记|
|'d'|小菱形标记|
|'|'|竖线标记|
|'_'|横线标记|

还有一些marker相关的参数：
|参数|说明|
|--|--|
|markeredgecolor|表示标记外边颜色|
|markeredgewidth|表示标记外边线宽|
|markerfacecolor|表示标记实心颜色|
|markersize|表示标记大小|
|label|表示该图的图例名称|

注：以上参数中除(x,y)为必需项以外，其他参数均为可选项。


**实例**

```
#建立一个坐标系
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])
>>>y = np.array([ 866, 2335, 5710, 6482, 6120, 1605, 3813, 4428, 4631])

#作图
>>>plt.plot(x,y,color="k",linestyle="dashdot",linewidth=1,marker="o",markersize=5,label="注册用户数")

#设置标题
>>>plt.title("XXX公司1-9月注册用户量",loc="center")#标题名以及标题的位置

#添加数据标签
>>>for a,b in zip(x,y):
       plt.text(a,b,b,ha='center', va= "bottom",fontsize=10)

>>>plt.grid(True)#设置网格线

>>>plt.legend()#设置图例，调用显示出plot中的label值

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/plot.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6iz4fpedj23vc2kwhdt.jpg)

### 13.8.2柱状图绘制

柱状图常用于比较不同类别之间的数据情况，使用的是plt库中的bar方法。

**参数详解**

```
plt.bar(x, height, width=0.8, bottom=None, align='center',color)
```
|参数|说明|
|--|--|
|x|表示在什么位置显示柱状图|
|height|表示每根柱子的高度|
|width|表示每根柱子的宽度，可以每根柱子的宽度都一样，也可以各不一样|
|bottom|表示每根柱子的底部位置，可以每根柱子的底部位置都一样，也可以各不一样|
|align|表示柱子的位置与x值的关系，有{center,edge}两个参数可选，center表示柱子位于x值的中心位置，edge表示柱子位于x值的边缘位置|
|color|柱子颜色|
|edgecolor|表示柱子边缘的颜色|


**普通柱状图实例**

```
#建立一个坐标系
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = np.array(["东区","南区","西区","北区"])
>>>y = np.array([ 8566, 5335, 7310, 6482])

#作图
>>>plt.bar(x,y,width=0.5,align="center",label="任务量")

#设置标题
>>>plt.title("全国各分区任务量",loc="center")

#添加数据标签
>>>for a,b in zip(x,y):
       plt.text(a,b,b,ha='center', va= "bottom",fontsize=12)
    
#设置x/y轴名称
>>>plt.xlabel('分区')
>>>plt.ylabel('任务量')

>>>plt.legend()#显示图例

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/bar.jpg")
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw6iz0ap0vj23vc2kw1kx.jpg)

**簇状柱状图实例**

簇状柱状图常用来表示不同类别随着同一变量的变化情况，使用的同样是plt库中的bar()方法，只不过需要调整柱子的显示位置。

```
#建立一个坐标系
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = np.array([1,2,3,4])
>>>y1 = np.array([8566,5335,7310,6482])
>>>y2 = np.array([4283,2667,3655,3241])

#作图
>>>plt.bar(x,y1,width=0.3,label="任务量")#柱形图的宽度为0.3
>>>plt.bar(x+0.3,y2,width=0.3,label="完成量")#让第二条柱形图的x值加第一条柱形图的宽度0.3，相当于把第二条柱形图右移

#设置标题
>>>plt.title("全国各分区任务量&完成量",loc="center")#标题名以及标题的位置

#添加数据标签
>>>for a,b in zip(x,y1):
       plt.text(a,b,b,ha='center', va= "bottom",fontsize=12)
    
>>>for a,b in zip(x+0.3,y2):
       plt.text(a,b,b,ha='center', va= "bottom",fontsize=12)
    
#设置x/y轴名称
>>>plt.xlabel('区域')
>>>plt.ylabel('任务情况')

#设置x轴刻度值
>>>plt.xticks(x+0.15,["东区","南区","西区","北区"])

>>>plt.grid(False)#设置网格线

>>>plt.legend()#图例设置

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/bar.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6iz1whutj23vc2kw4qp.jpg)

**堆积柱状图实例**

堆积柱状图常用来比较同类别各变量和不同类别变量的总和差异，使用的同样是plt库中的bar()方法，只需在相同的x位置绘制不同的y,y会自动叠加。

```
#建立一个坐标系
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = np.array(["东区","南区","西区","北区"])
>>>y1 = np.array([8566,5335,7310,6482])
>>>y2 = np.array([4283,2667,3655,3241])

#作图
>>>plt.bar(x,y1,width=0.3,label="任务量数")#柱形图的宽度为0.3
>>>plt.bar(x,y2,width=0.3,label="完成量")#让第二条柱形图的x值加第一条柱形图的宽度0.3，相当于把第二条柱形图右移

#设置标题
>>>plt.title("全国各分区任务量&完成量",loc="center")#标题名以及标题的位置

#添加数据标签
>>>for a,b in zip(x,y1):
       plt.text(a,b,b,ha='center', va= "bottom",fontsize=12)
    
>>>for a,b in zip(x,y2):
       plt.text(a,b,b,ha='center', va= "top",fontsize=12)
    
#设置x/y轴名称
>>>plt.xlabel('区域')
>>>plt.ylabel('任务情况')

>>>plt.grid(False)#设置网格线

#图例设置
>>>plt.legend(loc = "upper center",ncol = 2)

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/bar.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6j103ocdj23vc2kw4qp.jpg)

### 13.8.3条形图绘制

条形图与柱状图类似，只不过是将x/y轴进行了调换,纵向柱状图变成了横向柱状图，使用的是plt库中的barh方法。

**参数详解**
```
plt.barh(y,width,height,align,color,edgecolor)
```
|参数|说明|
|--|--|
|y|表示在什么位置显示柱子,即纵坐标|
|width|表示柱子在横向的宽度，即横坐标|
|height|表示柱子在纵向的高度，即柱子的实际宽度|
|align|表示柱子的对齐方式|
|color|表示柱子的颜色|
|edgecolor|表示柱子边缘颜色|

**实例**

```
#建立一个坐标系
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = np.array(["东区","南区","西区","北区"])
>>>y = np.array([ 8566, 5335, 7310, 6482])

#作图
>>>plt.barh(x,height=0.5,width=y,align="center")#width指明柱形图的宽度，align指明柱状图的位置，还可以选edge，默认是center

#设置标题
>>>plt.title("全国各分区任务量",loc="center")

#添加数据标签
>>>for a,b in zip(x,y):
       plt.text(b,a,b,ha='center', va= "center",fontsize=12)
    
#设置x/y轴名称
>>>plt.ylabel('区域')
>>>.xlabel('任务量')

>>>plt.grid(False)#设置网格线

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/barh.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6mldx0hjj23vc2kw1kx.jpg)

### 13.8.4散点图绘制

散点图常用来发现各变量之间的相关关系，使用的是plt库中的scatter方法。

**参数详解**
```
>>>plt.scatter(x,y,s,c,marker,linewidths,edgecolors)
```


**实例**

```
#建立一个坐标系
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = [5.5,6.6,8.1,15.8,19.5,22.4,28.3,28.9]
>>>y = [2.38,3.85,4.41,5.67,5.44,6.03,8.15,6.87]

#作图
>>>plt.scatter(x,y,marker="o",s=100)

#设置标题
>>>plt.title("1-8月平均气温&啤酒销量关系图",loc="center")
    
#设置x/y轴名称
>>>plt.xlabel('平均气温')
>>>plt.ylabel('啤酒销量')
    
>>>plt.grid(False)#设置网格线

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/scatter.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6k9ge2mtj23vc2kwh9o.jpg)

### 13.8.5气泡图绘制

气泡图与散点图类似，散点图中各点的大小一致，气泡图中各点的大小不一致，使用的方法同样是plt库中的scatter方法，只需要让不同点的大小不一样即可。

**参数详解**

气泡图中的参数与散点图中的参数完全一致。

**实例**

```
#建立一个坐标系
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = np.array([5.5,6.6,8.1,15.8,19.5,22.4,28.3,28.9])
>>>y = np.array([2.38,3.85,4.41,5.67,5.44,6.03,8.15,6.87])

#作图
>>>colors = y*10#根据y值的大小生成不同的颜色
>>>area = y*100#根据y值的大小生成不同大小的形状

>>>plt.scatter(x,y,c = colors,marker = "o",s = area)

#设置标题
>>>plt.title("1-8月平均气温&啤酒销量关系图",loc="center")

#添加数据标签
>>>for a,b in zip(x,y):
       plt.text(a,b,b,ha='center', va= "center",fontsize=10,color = "white")
    
#设置x/y轴名称
>>>plt.xlabel('平均气温')
>>>plt.ylabel('啤酒销量')
    
>>>plt.grid(False)#设置网格线

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/scatter.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6kc6c4wcj23vc2kwtzb.jpg)

### 13.8.6面积图绘制
面积图是与折线图类似的一种图形，使用的是plt库中的stackplot方法。

**参数详解**
```
plt.stackplot(x,y,labels,colors)
```

|参数|说明|
|--|--|
|(x,y)|x/y坐标数值|
|labels|不同系列图表的图例名|
|colors|不同系列图表的颜色|

**实例**

```
#建立一个坐标系
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]
>>>y1 = array([ 866, 2335, 5710, 6482, 6120, 1605, 3813, 4428, 4631])
>>>y2 = array([ 433, 1167, 2855, 3241, 3060,  802, 1906, 2214, 2315])

#作图
>>>labels = ["注册人数 ", "激活人数"] #指明系列标签
>>>plt.stackplot(x,y1,y2,labels=labels)


#设置标题
>>>plt.title("XXX公司1-9月注册&激活用户量",loc="center")
    
#设置x/y轴名称
>>>plt.xlabel('月份')
>>>plt.ylabel('注册&激活量')
    
>>>plt.grid(False)#设置网格线

>>>plt.legend()

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/stackplot.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6lkc7p4rj23vc2kw4qp.jpg)

### 13.8.7树地图绘制

树地图常用来表示同一等级中不同类别的占比关系，使用的是squarify库，在使用这个库以前先需要安装一下，安装方法是`pip install squarify。

```
squarify.plot(sizes,label,color,value,edgecolor,linewidth)
```
|参数|说明|
|--|--|
|sizes|待绘图数据|
|label|不同类别图例标签|
|color|不同类别颜色|
|value|不同类别数据标签|
|edgecolor|不同类别之间边框颜色|
|linewidth|边框线宽|

**实例**

```
import squarify

#指定每一块的大小
size = np.array([0.34,0.693,0.585,0.570,0.562,0.531,0.530,0.524,0.501,0.478,0.468,0.436])

#指定每一块的文字标签
xingzuo = np.array(["未知","摩羯座","天秤座","双鱼座","天蝎座","金牛座","处女座","双子座","射手座","狮子座","水瓶座","白羊座","巨蟹座"])

#指定每一块的数值标签
rate = np.array(["34%","6.93%","5.85%","5.70%","5.62%","5.31%","5.30%","5.24%","5.01%","4.78%","4.68%","4.36%"])

#指定每一块的颜色
colors = ['steelblue','#9999ff','red','indianred',
          'green','yellow','orange']

#绘图
plot = squarify.plot(sizes = size, 
                     label = xingzuo, 
                     color = colors,
                     value = rate,
                     edgecolor = 'white',
                     linewidth =3
                    )

# 设置标题大小
plt.title('菊粉星座分布',fontdict = {'fontsize':12})

# 去除坐标轴
plt.axis('off')

# 去除上边框和右边框刻度
plt.tick_params(top = 'off', right = 'off')

#保存图表到本地
plt.savefig("C:/Users/zhangjunhong/Desktop/squarify.jpg")

```

![](https://i.loli.net/2018/10/22/5bcca40fb31c3.png)

### 13.8.8雷达图绘制

雷达图常用来综合评价某一个事物，可以直观地看出某一事物的优势与不足，使用的方法是plt库中的polar方法，polar是用来建立极坐标系的，其实雷达图就是先将各点展示在极坐标系中，然后再用线将各点连接起来。

**参数详解**
```
plt.polar(theta,r,color,marker,linewidth)
```

|参数|说明|
|--|--|
|theta|每一点的在极坐标系中的角度|
|r|每一点的在极坐标系中的半径|
|color|连接各点之间线的颜色|
|marker|每点的标记物|
|linewidth|连接线的宽度|

**实例**

```
#建立坐标系
>>>plt.subplot(111,polar = True)#参数polar等于True表示建立一个极坐标系

>>>dataLenth = 5#把整个圆切分成5份
>>>angles = np.linspace(0, 2*np.pi, dataLenth, endpoint=False)#np.linspace表示在指定的间隔内返回均匀间隔的数字
>>>labels = ['沟通能力','业务理解能力','逻辑思维能力','快速学习能力','工具使用能力']
>>>data = [2,3.5,4,4.5,5]

>>>data = np.concatenate((data, [data[0]])) # 闭合
>>>angles = np.concatenate((angles, [angles[0]])) # 闭合

#绘图
>>>plt.polar(angles,data,color = "r",marker = "o")

#设置x轴刻度
>>>plt.xticks(angles,labels)

#设置标题
>>>plt.title(s = "某数据分析师的综合评级")

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/polarplot.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6lkb1hynj23vc2kwe81.jpg)

### 13.8.9箱形图绘制
箱形图是用来反映一组数据离散情况的图表，使用的方法是plt库中的boxplot方法。

**参数详解**
```
plt.boxplot(x,vert,whis,labels)
```
|参数|说明|
|--|--|
|x|待绘图源数据|
|vert|箱形图方向，如果为True则表示纵向；如果为False则表示横向；默认为True|
|widths|箱形图宽度|
|labels|箱形图标签|

**实例**
```
#建立一个坐标系
>>>plt.subplot(1,1,1)

#指明x值
>>>y1 = array([ 866, 2335, 5710, 6482, 6120, 1605, 3813, 4428, 4631])
>>>y2 = array([ 433, 1167, 2855, 3241, 3060,  802, 1906, 2214, 2315])
>>>x = [y1,y2]

#作图
>>>labels=["注册人数","激活人数"]
>>>plt.boxplot(x,labels=labels,vert=True,widths = [0.2,0.5])

#设置标题
>>>plt.title("XXX公司1-9月注册&激活人数",loc="center")
    
>>>plt.grid(False)#设置网格线

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/boxplot.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6movkqtpj23vc2kwkh4.jpg)

>注：上面的x和labels也可以是只有一个

### 13.8.10饼图绘制

饼图也常用来表示同一等级中不同类别的占比情况，使用的方法是plt库中的pie方法。

**参数详解**
```
plt.pie(x,explode,labels,colors,autopct,pctdistance,shadow,labeldistance,startangle,radius,counterclock,wedgeprops,textprops,center,frame)
```

|参数|说明|
|--|--|
|x|待绘图数据|
|explode|饼图中每一块离圆心的距离|
|labels|饼图中每一块的标签|
|colors|饼图中每一块的颜色|
|autopct|控制饼图内数值的百分比格式|
|pctdistance|数据标签距离中心的距离|
|shadow|饼图是否有阴影|
|labeldistance|每一块索引距离中心的距离|
|startangle|饼图的初始角度|
|radius|饼图半径|
|counterclock|是否让饼图逆时针显示|
|wedgeprops|饼图内外边界属性|
|textprops|饼图中文本相关属性|
|center|饼图中心位置|
|frame|是否显示饼图背后图框|

**实例**

```
#建立一个坐标系
>>>plt.subplot(1,1,1)

#指明x值
>>>x = np.array([ 8566, 5335, 7310, 6482])

>>>labels=["东区","北区","南区","西区"]
>>>explode=[0.05,0,0,0]#让第一块离圆心远一点
>>>labeldistance=1.1
>>>plt.pie(x,labels=labels,autopct='%.0f%%',shadow=True,explode=explode,radius=1.0,labeldistance=labeldistance)

#设置标题
>>>plt.title("全国各区域任务量占比",loc="center")

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/pie.jpg")
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw6lumryfvj23vc2kwqqw.jpg)

### 13.8.11圆环图绘制
圆环图是与饼图类似的一种图表，常用来表示同一层级不同类别之间的占比关系，使用的方法也是plt库中pie方法。

**参数详解**

圆环图的参数与饼图的参数完全一致。

**实例**

圆环图的实现是在饼图的基础上调整wedgeprops参数。

```
#建立坐标系
>>>plt.subplot(1,1,1)

#指明x值
>>>x1 = np.array([ 8566, 5335, 7310, 6482])
>>>x2 = np.array([4283,2667,3655,3241])

#作图
>>>labels = ["东区","北区","南区","西区"]
>>>plt.pie(x1,labels=labels,radius=1.0,wedgeprops=dict(width=0.3, edgecolor='w'))
>>>plt.pie(x2,radius=0.7,wedgeprops=dict(width=0.3, edgecolor='w'))

#添加注释
>>>plt.annotate("完成量",xy = (0.35,0.35),xytext = (0.7,0.45),arrowprops=dict(facecolor='black',arrowstyle = '->'))
>>>plt.annotate("任务量",xy = (0.75,0.20),xytext = (1.1,0.2),arrowprops=dict(facecolor='black',arrowstyle = '->'))

#设置标题
>>>plt.title("全国各区域任务量&完成量占比",loc="center")#标题名以及标题的位置

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/pie.jpg")
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw6m6abrqzj23vc2kwx6h.jpg)


### 13.8.12热力图绘制

热力图是将某一事物的响应度反映在图表上，可以快速发现需重点关注的区域，使用的方法是plt库中的imshow方法。

**参数详解**

```
plt.imshow(x,cmap)
```
|参数|说明|
|--|--|
|x|表示待绘图的数据，需要是矩阵形式|
|cmap|配色方案，用来表面图表渐变的主题色|

cmap的所有可选值都封装plt.cm里面，在jupyter_notebook中输入`plt.cm.`然后点击Tab键就可以看到，如下：

![](https://ws1.sinaimg.cn/large/7602070dly1fw6pomn5icj20au084wex.jpg)

**实例**

```
#几个指标相关之间的相关性
>>>x = np.array([[1,0.082,0.031,-0.0086],
                [0.082,1,-0.063,0.062],
                [0.031,-0.09,1,0.026],
                [-0.0086,0.062,0.026,1]])

>>>cmap=plt.cm.cool#设置配色方案
>>>plt.imshow(cm,cmap = cmap)
>>>plt.colorbar()#显示右边的颜色条

#设置x/y轴的刻度标签
>>>classes=["负债率","信贷数量","年龄","家属数量"]
>>>tick_marks = np.arange(len(classes))
>>>plt.xticks(tick_marks,classes)
>>>plt.yticks(tick_marks,classes)


#将数值显示在指定位置
>>>for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
       plt.text(j, i,cm[i, j],horizontalalignment="center")

>>>plt.grid(False)#设置网格线

#保存图表到本地
>>>plt.savefig("C:/Users/zhangjunhong/Desktop/imshow.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6ptp866lj23vc2kw7wh.jpg)

### 13.8.13水平线和垂直线绘制

水平线和垂直线主要用来做对比参考作用，使用的是plt库中的axhline和axvline方法。

**参数详解**

```
plt.axhline(y,xmin,xmax)
plt.axvline(x,ymin,ymax)
```

|参数|说明|
|--|--|
|y/x|画水平/垂直线时的横/纵坐标|
|xmin/xmax|水平线的起点和终点|
|ymin/ymax|垂直线的起点和终点|

```
#建立坐标系
>>>plt.subplot(1,2,1)

#绘制一条y等于2且起点是0.2终点是0.6的水平线
>>>plt.axhline(y = 2,xmin = 0.2,xmax = 0.6)

>>>plt.subplot(1,2,2)

#绘制一条x等于2且起点是0.2终点是0.6的垂直线
>>>plt.axvline(x = 2,ymin = 0.2,ymax = 0.6)
```

![](https://ws1.sinaimg.cn/large/7602070dly1fw014n21vlj23vc2kwgur.jpg)

## 13.9组合图表绘制
组合图表就是在同一坐标系中绘制多张图表，常见的有折线图+折线图、折线图+柱状图、柱状图+柱状图等几种形式。柱状图+柱状图其实就是簇状柱状图。
### 13.9.1折线图+折线图
折线图+折线图就是将大于等于两条以上的折线画在同一坐标系中，具体绘制方法就是在建立坐标系以后，直接运行多行绘制折线图代码即可，实例如下：

```
#建立一个坐标轴
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]
>>>y1 = np.array([ 866, 2335, 5710, 6482, 6120, 1605, 3813, 4428, 4631])
>>>y2 = np.array([ 433, 1167, 2855, 3241, 3060,  802, 1906, 2214, 2315])

#直接绘制两条折线
>>>plt.plot(x,y1,color="k",linestyle="solid",linewidth=1,marker="o",markersize=3,label="注册人数")
>>>plt.plot(x,y2,color="k",linestyle="dashdot",linewidth=1,marker="o",markersize=3,label="激活人数")

#设置标题
>>>plt.title("XXX公司1-9月注册&激活人数",loc="center")#标题名以及标题的位置

#添加数据标签
>>>for a,b in zip(x,y1):
       plt.text(a,b,b,ha='center', va= "bottom",fontsize=11)
    
>>>for a,b in zip(x,y2):
       plt.text(a,b,b,ha='center', va= "bottom",fontsize=11)
    
#设置x/y轴名称
>>>plt.xlabel('月份')
>>>plt.ylabel('注册量')

#设置x/y轴刻度
>>>plt.xticks(np.arange(1,10,1),["1月份","2月份","3月份",
            "4月份","5月份","6月份","7月份","8月份","9月份"])
>>>plt.yticks(np.arange(1000,7000,1000),
            ["1000人","2000人","3000人","4000人","5000人","6000人"])

>>>plt.legend()#设置图例

#保存文件到本地
>>>plt.savefig(r"C:\Users\zhangjunhong\Desktop\plot2.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6qox656sj23vc2kwe81.jpg)

### 13.9.2折线图+柱状图

折线图+柱状图与折线图+折线图绘制原理一样，建立好坐标系以后，先运行一行代码来绘制折线图，然后再运行一行代码来绘制柱状图，这样两个图表就显示在一个坐标系中，如果想将其他组合图表绘制在同一坐标系中也是同样的道理，实例如下：

```
#建立一个坐标轴
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])
>>>y1 = np.array([ 866, 2335, 5710, 6482, 6120, 1605, 3813, 4428, 4631])
>>>y2 = np.array([ 433, 1167, 2855, 3241, 3060,  802, 1906, 2214, 2315])

#直接绘制两条折线
>>>plt.plot(x,y1,color="k",linestyle="solid",linewidth=1,marker="o",markersize=3,label="注册人数")
>>>plt.bar(x,y2,color="k",label="激活人数")

#设置标题
>>>plt.title("XXX公司1-9月注册&激活人数",loc="center")#标题名以及标题的位置

#添加数据标签
>>>for a,b in zip(x,y1):
       plt.text(a,b,b,ha='center', va= "bottom",fontsize=11)
    
>>>for a,b in zip(x,y2):
       plt.text(a,b,b,ha='center', va= "bottom",fontsize=11)
    
#设置x/y轴名称
>>>plt.xlabel('月份')
>>>plt.ylabel('注册量')

#设置x/y轴刻度
>>>plt.xticks(np.arange(1,10,1),["1月份","2月份","3月份",
            "4月份","5月份","6月份","7月份","8月份","9月份"])
>>>plt.yticks(np.arange(1000,7000,1000),
            ["1000人","2000人","3000人","4000人","5000人","6000人"])

>>>plt.legend()#设置图例

#保存文件到本地
>>>plt.savefig(r"C:\Users\zhangjunhong\Desktop\bar2.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6qotos7lj23vc2kwe81.jpg)

## 13.10双坐标轴图表绘制
双坐标轴图表就是既有主坐标轴又有次坐标轴的图表，当两个不同量级的指标要放在同一坐标系中时，就需要开启双坐标轴，比如任务量和完成率就是两个不同量级的指标。

### 13.10.1双y轴图表绘制
双y轴图表绘制就是一个坐标系中有两条y轴，使用的是plt库中的twinx方法，具体绘制流程为：先建立坐标系，然后绘制主坐标轴上的图表，再调用plt.twinx方法，最后绘制次坐标轴上的图表，实例如下：

```
#建立一个坐标轴
>>>plt.subplot(1,1,1)

#指明x和y值
>>>x = np.array([1,2,3,4,5,6,7,8,9])
>>>y1 = np.array([ 866, 2335, 5710, 6482, 6120, 1605, 3813, 4428, 4631])
>>>y2 = np.array([0.54459448, 0.32392354, 0.39002751, 0.41121879, 0.32063077, 0.33152276, 0.92226226, 0.02950071, 0.15716906])

#绘制主坐标轴的图表
>>>plt.plot(x,y1,color="k",linestyle="solid",linewidth=1,marker="o",markersize=3,label="注册人数")

#设置主x/y轴名称
>>>plt.xlabel('月份')
>>>plt.ylabel('注册量')

#设置主坐标轴图表的图例
>>>plt.legend(loc = "upper left")

#调用twinx方法
>>>plt.twinx()

#绘制次坐标轴的图表
>>>plt.plot(x,y2,color="k",linestyle="dashdot",linewidth=1,marker="o",markersize=3,label="激活率")

#设置次x/y轴名称
>>>plt.xlabel('月份')
>>>plt.ylabel('激活率')

#设置次坐标轴图表的图例
>>>plt.legend()

#设置标题
>>>plt.title("XXX公司1-9月注册量&激活率",loc="center")#标题名以及标题的位置

#保存图表文件到本地
>>>plt.savefig(r"C:\Users\zhangjunhong\Desktop\twinx.jpg")
```
![](https://ws1.sinaimg.cn/large/7602070dly1fw6rq8ixprj23vc2kw7wh.jpg)

### 13.10.2双x轴图表绘制
双x轴绘制就是一个坐标系中有两条x轴，使用的是plt库中的twiny方法，具体的流程和双y轴图表绘制完全一样，在实际业务中使用较少。

## 13.11绘图样式设置
matplotlib默认的样式看起来都不是那么好看，但是他支持你调用其他样式，让你有更多的选择。使用`plt.style.available`即可看到matplotlib支持的所有样式表，如下：

```
>>>plt.style.available
['bmh',
 'classic',
 'dark_background',
 'fast',
 'fivethirtyeight',
 'ggplot',
 'grayscale',
 'seaborn-bright',
 'seaborn-colorblind',
 'seaborn-dark-palette',
 'seaborn-dark',
 'seaborn-darkgrid',
 'seaborn-deep',
 'seaborn-muted',
 'seaborn-notebook',
 'seaborn-paper',
 'seaborn-pastel',
 'seaborn-poster',
 'seaborn-talk',
 'seaborn-ticks',
 'seaborn-white',
 'seaborn-whitegrid',
 'seaborn',
 'Solarize_Light2',
 '_classic_test']
```

如果你要使用这其中的某种样式，只需要在程序的最开头加上下面的这一行代码即可：

```
>>>plt.style.use(样式名)
```

需要注意的一点是，一旦在一段程序中运行了上面那行代码，指明了使用哪种样式，则在该程序中接下来的所有图表都会使用这种样式。

下面列举了前面的几种样式，大家可以感受一下效果：

**默认样式**

![](https://ws1.sinaimg.cn/large/7602070dly1fw6xhptxjbj23vc2kwtz7.jpg)

**bmh样式**

![](https://ws1.sinaimg.cn/large/7602070dly1fw6xhm3cs1j23vc2kw4qp.jpg)

**classic样式**

![](https://ws1.sinaimg.cn/large/7602070dly1fw6xhymo6jj23vc2kwnoe.jpg)

**dark_back_ground样式**

![](https://ws1.sinaimg.cn/large/7602070dly1fw6xho9omvj23vc2kw7tz.jpg)

**fast样式**

![](https://ws1.sinaimg.cn/large/7602070dly1fw6xhwxo1zj23vc2kwtz7.jpg)

**fivethirtyeight样式**

![](https://ws1.sinaimg.cn/large/7602070dly1fw6xhrxmd0j23vc2kw1kx.jpg)

**ggplot样式**

![](https://ws1.sinaimg.cn/large/7602070dly1fw6xht973nj23vc2kwe75.jpg)

**grayscale样式**

![](https://ws1.sinaimg.cn/large/7602070dly1fw6xhve8b0j23vc2kw4mz.jpg)

**seaborn-bright样式**

![](https://ws1.sinaimg.cn/large/7602070dly1fw6xhymo6jj23vc2kwnoe.jpg)

# 第十四章:实战案例

## 14.1利用Python让你的报表自动化
作为一个数据分析师，经常要做很多报表，表太多的时候就只顾做表，根本没有时间去做分析。但是一个数据分析师的核心价值应该是通过报表发现数据背后隐藏的信息，而不是简单的数据罗列，如果只是简单的数据罗列其实就不算作数据分析师，而是一个“表哥”。但实际工作中我们还是避免不了要做一些“表哥”的工作，怎么办呢？把这些固定的“表哥”型工作写成脚本，让程序自己去做。这样我们就有更多的时间去做分析了。我们把让程序自己运行的这个过程叫做自动化。
### 14.1.1为什么要进行报表自动化
**提高工作效率**

前面说过，我们可以把一些“表哥”型的工作写成脚本，让程序自己去做。这样会节省下很多时间，让我们去做更多有价值有意义的工作。

**减少错误**

只要涉及到人手动做的事情就有可能出错，比如中日报中你每天需要修改一下当天的日期，如果这个事情每天都需要你手动去做，说不准哪天你心情不太好，工作不在状态就会把这个给忘记了。如果忘记修改，数据就是错的。但是程序是不会忘记的，你只需要告诉程序每天怎么去做就可以了。通过自动化可以减少我们出错的概率。
### 14.1.2什么样的报表适合自动化
虽然自动化的好处显而易见，但并不是所有的报表都适合自动化，对报表进行自动化的时候我们需要综合考虑以下几个方面:

**使用频率**

对于日报、周报、月报等常规的、使用频率较高的报表，有必要去进行自动化，而偶尔使用的一些报表就没有必要去进行自动化。

**开发时间**

对报表进行自动化需要写相应的脚本去实现，有的自动化实现起来比较难，写脚本耗费的时间也可能比较久，这个时候就需要衡量一下开发脚本所耗费的时间和自己人工做表所耗费的时间差了。

**需求变更频率**

需求变更频率就是指报表里涉及的指标以及展现方式的变更频率。如果你做的报表是为了反映一个新业务的发展情况，这个时候报表的变更频率就会比较大，因为一个新的业务需要不停地去尝试不同的方向，这个时候是不适合去做自动化的。但如果是相对比较成熟的业务，报表格式也相对比较固定了。这个时候就可以考虑去做自动化。

**流程是否标准**

因为自动化是需要让计算机自己去完成，所以制作流程应该是比较标准的，这样有利于计算机理解每一步该干什么。


### 14.1.3如何进行报表自动化

如何进行自动化，其实就是一句话，把人工做的事情交给计算机，你怎么做，告诉计算机怎么做就可以。你第一步干什么、第二步干什么，同样也告诉计算机，只要你告诉了他，以后他就可以自动完成了，这就是自动化。

接下来我们拿一个小案例给大家演示一下，具体该怎么自动化。比如我们现在每天需要做如下这个表，做销售额、客流量、客单价这三个指标的本月累计、上月同期、去年同期、同环比这几个数值。

![](https://ws1.sinaimg.cn/large/7602070dly1fw7gq64rwqj20fa035dfs.jpg)

假设你每天做报表的源数据是存放在一张订单表里面，这里包含了从去年到至今的所有订单数据，如下为部分数据：

![](https://i.loli.net/2018/10/20/5bcaca91809e9.png)

```
#指标说明
销售额 = 单价*销量
客流量 = 订单ID去重计数
客单价 = 销售额/客流量
本月 = 2018年2月
上月 = 2018年1月
去年同期 = 2018年2月
```

开始正式的报表制作过程，为了便于大家理解代码，所以将整个过程分成若干个小的过程来实现。

**导入源数据**

直接利用pandas模块中的read_csv将源数据导入进来即可。

```
>>>import pandas as pd
>>>from datetime import datetime
>>>data = pd.read_csv(r"C:\Users\Desktop\order.csv",parse_dates = ["成交时间"])
>>>data.head()#预览数据
>>>data.info()#查看源数据类型
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 6148 entries, 0 to 6147
Data columns (total 6 columns):
商品ID    3478 non-null float64
类别ID    3478 non-null float64
单价      3478 non-null float64
销量      3478 non-null float64
成交时间    3478 non-null datetime64[ns]
订单ID    3478 non-null object
dtypes: datetime64[ns](1), float64(4), object(1)
memory usage: 288.3+ KB
```

parse_dates参数表示将数据解析为时间格式。

**计算本月相关指标**

首先根据成交时间将本月的全部数据索引出来，然后在本月订单数据的基础上再去进行运算。

```
>>>This_month = data[(data["成交时间"] >= datetime(2018,2,1))&
                (data["成交时间"] <= datetime(2018,2,28))]
>>>sales_1 = (This_month["销量"]*This_month["单价"]).sum()#销售额计算
>>>traffic_1 = This_month["订单ID"].drop_duplicates().count()#客流量计算
>>>s_t_1 = sales/traffic#客单价计算
>>>print("本月销售额为:{:.2f},客流量为:{},客单价为:{:.2f}".format(sale_1,traffic_1,s_t_1))
本月销售额为:9572.66,客流量为:480,客单价为:19.94
```


**计算上月相关指标**

上月相关指标的计算逻辑与本月计算逻辑完全一样，只不过数据范围是上月，首先根据成交时间将上月的全部数据索引出来，然后在上月订单数据的基础上再去进行运算。

```
>>>last_month = data[(data["成交时间"] >= datetime(2018,1,1))&
                (data["成交时间"] <= datetime(2018,1,31))]
>>>sales_2 = (last_month["销量"]*last_month["单价"]).sum()#销售额计算
>>>traffic_2 = last_month["订单ID"].drop_duplicates().count()#客流量计算
>>>s_t_2 = sales/traffic#客单价计算
>>>print("本月销售额为:{:.2f},客流量为:{},客单价为:{:.2f}".format(sale_2,traffic_2,s_t_2))
本月销售额为:7345.79,客流量为:361,客单价为:20.35
```

**计算去年同期相关指标**

去年同期相关指标的计算逻辑与本月计算逻辑完全一样，数据范围换成去年同期的时间，首先根据成交时间将去年同期的全部数据索引出来，然后在去年同期订单数据的基础上再去进行运算。

```
>>>same_month = data[(data["成交时间"] >= datetime(2017,2,1))&
                (data["成交时间"] <= datetime(2017,2,28))]
>>>sales_3 = (same_month["销量"]*same_month["单价"]).sum()#销售额计算
>>>traffic_3 = same_month["订单ID"].drop_duplicates().count()#客流量计算
>>>s_t_3 = sales/traffic#客单价计算
>>>print("本月销售额为:{:.2f},客流量为:{},客单价为:{:.2f}".format(sale_3,traffic_3,s_t_3))
本月销售额为:12031.62,客流量为:565,客单价为:21.29
```

**利用函数提高编码效率**

大家有没有发现上面三个时间段内相关指标的计算逻辑都一样，唯一不同的就是在哪一部分订单数据上进行计算，我们回想一下函数的定义，就是一段可以重复利用程序代码，我们可以利用函数来计算上述三个时间段内的指标：

```
>>>def get_month_data(data):
       sale = (data["Price"]*data["Qty"]).sum()
       traffic = data["SheetID"].drop_duplicates().count()
       s_t = sale/traffic
       return (sale,traffic,price)

#计算本月相关指标
>>>sale_1,traffic_1,s_t_1 = get_month_data(This_data)

#计算上月相关指标
>>>sale_2,traffic_2,s_t_2 = get_month_data(last_data)

#计算去年同期相关指标
>>>sale_3,traffic_3,s_t_3 = get_month_data(same_data)
```


**将三个时间段指标进行合并**

```
>>>report = pd.DataFrame([[sale_1,sale_2,sale_3],
                         [traffic_1.traffic_2,traffic_3],
                         [s_t_1,s_t_2,s_t_3]],
                         columns = ["本月累计","上月累计","去年同期"]
                         index = ["销售额","客流量","客单价"])
>>>report
	    本月累计	环比上月	去年同期
销售额	9573.0      7346.0	    12032.0
客流量	480.0	    361.0     	565.0
客单价	20.0	    20.0	    21.0

#添加同比和环比字段
>>>report["环比"] = report["本月累计"]/report["环比上月"] - 1
>>>report["同比"] = report["本月累计"]/report["去年同期"] - 1
>>>report
	    本月累计 环比上月 去年同期	环比	同比
销售额	9573.0	 7346.0	  12032.0	0.303158	-0.204372
客流量	480.0	 361.0	  565.0  	0.329640	-0.150442
客单价	20.0	 20.0	  21.0   	0.000000	-0.047619
```

**将结果文件导出到本地**

```
>>>report.to_csv(r"C:\Users\Desktop\order.csv",encoding = "utf-8-sig")
```

上面所有的步骤只要你都事先编写好了，那么每次当你需要这个表的时候，只需要点击运行，就会在你的目标文件夹下面生成一个结果文件，省去了你自己人工做的时间。

上面的报表看起来可能比较简单，但不管多么复杂的报表，都是同样的实现原理，你只需要把每一步需要干什么告诉计算机，告诉完以后，当你需要做的时候，直接点击运行，程序就会出来你想要的结果。

## 14.2自动发送电子邮件
我们把报表做出来以后一般都是需要发给别人查看，对于一些每天需要发的报表或者是需要发送多份的时候，这个时候可以考虑借助Python来自动发送邮件。

在利用Python进行发送邮件时主要借助smtplib和email两个模块，其中smtplib主要用来建立服务器链接、服务器断开的工作，而email模块主要用来设置一些与邮件本身相关的内容，比如收件人、发件人、主题之类的。

不同邮箱的服务器链接地址不一样，大家根据自己使用的邮箱设置相应的服务器链接。163邮箱还是相对比较常用的，所以这里就以163邮箱为例，给大家演示一下具体如何利用Python进行自动发送邮件。

在开始进行正式代码之前，需要先登陆自己的163邮箱进行授权设置，授权码设置如下：

![](https://i.loli.net/2018/10/20/5bcaeed636c85.png)

点击设置中的`POP3/SMTP/IMAP`，勾选SMTP服务，根据提是进行授权码设置，设置授权成功后，在Python中利用授权码进行登陆，而不是你本来的邮箱密码，如果使用本来的邮箱密码登陆，会报错。

```
>>>import smtplib
>>>from email import encoders
>>>from email.header import Header
>>>from email.mime.text import MIMEText
>>>from email.utils import parseaddr, formataddr
>>>from email.mime.application import MIMEApplication

#发件人邮箱
>>>asender="zhangjunhongdata@163.com"
#收件人邮箱
>>>areceiver="zhangjunhong@163.com"
#抄送人邮箱
>>>acc = 'zhangjunhong@qq.com'
#邮件主题
>>>asubject = '这是一份测试邮件'  

#发件人地址
>>>from_addr = "zhangjunhongdata@163.com"
#邮箱密码（授权码）
>>>password="123data"

#邮件设置
>>>msg = MIMEMultipart()
>>>msg['Subject'] = asubject  
>>>msg['to'] = areceiver  
>>>msg['Cc'] = acc 
>>>msg['from'] =  "张俊红"

#邮件正文
>>>body = "你好，这是一份测试邮件"

#添加邮件正文:
>>>msg.attach(MIMEText(body, 'plain', 'utf-8'))

#添加附件
#注意这里的文件路径是斜杠
>>>xlsxpart = MIMEApplication(open('C:/Users/zhangjunhong/Desktop/这是附件.xlsx', 'rb').read())
>>>xlsxpart.add_header('Content-Disposition', 'attachment', filename='这是附件.xlsx')
>>>msg.attach(xlsxpart)    

#设置邮箱服务器地址以及端口
>>>smtp_server ="smtp.163.com"
>>>server = smtplib.SMTP(smtp_server, 25)
>>>server.set_debuglevel(1)
#登陆邮箱
>>>server.login(from_addr, password)
#发送邮件
>>>server.sendmail(from_addr, >>>areceiver.split(',')+acc.split(','), msg.as_string())
#断开服务器链接
server.quit()
```

最后的结果如下图：

![](https://i.loli.net/2018/10/20/5bcaf4d6b9e2d.png)

如果是需要同时发送多份邮件，可以把上述邮件发送过程定义成一个函数，把收件人以及其他内容生成一个列表，然后遍历每一个收件人，最后调用发送邮件函数进行多份邮件发送。

关于自动发送邮件还有很多内容，比如定时发送，正文显示html内容，附件添加图片等，大家有兴趣的可以自行上网搜索学习。

## 14.3假如你是某连锁超市数据分析师
假如你是一家连锁超市的数据分析师，以下几个问题可能会是你经常需要关注的。数据源如下表：
![](https://i.loli.net/2018/10/20/5bcafe5cf1189.png)

```
#导入数据源
>>>data = pd.read_csv(data = pd.read_csv(r"C:\Users\Desktop\order.csv",parse_dates = ["成交时间"]))
```

### 14.3.1哪些类别的商品比较畅销
要看哪些类别的商品比较畅销，只需要将订单表中的数据按照类别ID进行分组，然后对分组后的数据销量进行求和，就会得到每一类别在一段时间内的总销量。
```
>>>data.groupby("类别ID")["销量"].sum().reset_index()
	类别ID	    销量
0	910000000	24.0
1	910010000	7.0
2	910010002	1.0
3	910010101	6.0
4	910010301	2.0
5	910010400	1.0
6	910010500	4.0
7	910020000	10.0
8	910020102	1.0
9	910020104	31.0
10	910020105	1.0
......
```

上面得到了所有类别在一段时间内对应的销量，我们想看销量最好的前10个类别，先对销量做一个降序排列，然后取前10行就可以。

```
>>>data.groupby("类别ID")["销量"].sum().reset_index()
    .sort_values(by = "销量",ascending = False).head(10)
	类别ID	    销量
240	922000003	425.328
239	922000002	206.424
251	923000006	190.294
216	915030104	175.059
238	922000001	121.355
367	960000000	121.000
234	920090000	111.565
249	923000002	91.847
237	922000000	86.395
247	923000000	85.845
```
### 14.3.2哪些商品比较畅销
计算哪些商品比较畅销，其实与计算哪些类别比较畅销的逻辑一致，上面咱们用了数据分组，这次咱们用数据透视表来计算哪些商品比较畅销,同样取前10个商品。

```
>>>pd.pivot_table(data_2017,index = "商品ID",values = "销量",
        aggfunc = "sum").reset_index().sort_values(by = "销量",ascending = False).head(10)
    商品ID	    销量
8	29989059	391.549
18	29989072	102.876
469	30022232	101.000
523	30031960	99.998
57	29989157	72.453
476	30023041	64.416
505	30026255	62.375
7	29989058	56.052
510	30027007	48.757
903	30171264	45.000
```
### 14.3.3不同门店的销售额占比
商品畅销程度直接用销量来表示就可以，销售额等于销量乘单价，我们的订单表中没有销售额这个字段，所以需要新增一个销售额字段。新增好字段以后，按照门店编号进行分组，对分组后的营业额进行求和运算，最后计算不同门店的销售额占比,并用饼图表示。

```
>>>data["销售额"] = data["销量"]*data["单价"]
>>>data.groupby("门店编号")["销售额"].sum()
门店编号
CDLG     10908.82612
CDNL     8059.47867
CDXL     9981.76166
Name: 销售额, dtype: float64
>>>data.groupby("门店编号")["销售额"].sum()/data["销售额"].sum()
门店编号
CDLG    0.376815
CDNL    0.278392
CDXL    0.344792
Name: 销售额, dtype: float64
#绘制饼图
>>>(data_2017.groupby("门店编号")["销售额"].sum()/data_2017["销售额"].sum()).plot.pie()
```
![](https://i.loli.net/2018/10/20/5bcb0d80b8b13.jpg)

### 14.3.4哪些时间是超市的客流高峰期
了解清楚哪些时间是超市客流的高峰期是很有必要的，可以很好地帮助超市管理人员提前布置协调工作人员，或者是帮助超市管理人员决定在什么时间段搞促销活动。

现在我们想知道一天中什么时间（哪个小时）是高峰期，要想找出高峰期时间，需要知道每个时间段对应的客流量，但是订单表中的成交时间既有日期又有时间，我们需要从中提取出小时数，这里依然用订单ID去重计数代表客流量。

```
#利用自定义时间格式函数strftime提取小时数
>>>data["小时"] = data["成交时间"].map(lambda x:int(x.strftime("%H")))
#小时&订单去重
>>>traffic = data[["小时","订单ID"]].drop_duplicates()
#求每小时内的客流量
>>>traffic.groupby("小时")["订单ID"].count().plot()
小时
6      10
7      37
8     106
9     156
10    143
11     63
13     30
14     36
15     17
16     50
17     73
18     71
19     71
20     39
21     16
Name: 订单ID, dtype: int64
#绘制每小时客流量折线图
>>>traffic.groupby("小时")["订单ID"].count().plot()
```
上述代码中之所以要对小时和订单进行去重处理是因为我们用的订单表是以商品ID为主键的，也就是在一个小时内的会出现多个相同的订单ID，这些订单ID来自于同一个人，所以算作一个人。

分小时客流量折线图如下，可以看出早上8点-10点之间是超市一天中的高峰期，下午17点-19点又有一个小高峰，比较符合人们真实的生活场景。

![](https://i.loli.net/2018/10/20/5bcb0d80e9de7.jpg)


## 14.4假如你是某银行数据分析师
假如你是某银行的数据分析师，那么坏账率肯定是你日常需要关注的重点指标，坏账率的高低主要会受哪些因素的影响呢？现在有一份历史借款人员明细表，我们通过这份历史记录来看一下坏账率都会受哪些因素的影响，记录表如下：
![](https://i.loli.net/2018/10/20/5bcb314d77f1f.png)

```
#导入数据源
>>>data = pd.read_csv(r"C:\Users\Desktop\loan.csv")
>>>data.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 150000 entries, 0 to 149999
Data columns (total 6 columns):
用户ID    150000 non-null int64
是否坏账    150000 non-null int64
年龄      150000 non-null int64
负债率     150000 non-null float64
月收入     120269 non-null float64
家属数量    146076 non-null float64
dtypes: float64(3), int64(3)
memory usage: 6.9 MB
```
### 14.3.1收入越高的人坏账率越低吗
按理来说收入越高的人越不缺钱，坏账率应该越低，实际情况是什么样子呢？我们通过数据来看一下。看上面表的基本信息中，收入是有缺失值的，所以在具体的分析以前，我们需要先做一个缺失值处理。这里选择用均值填充，如下：

```
>>>data = data.fillna({"月收入":data["月收入"].mean()})
>>>data.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 150000 entries, 0 to 149999
Data columns (total 6 columns):
用户ID    150000 non-null int64
好坏客户    150000 non-null int64
年龄      150000 non-null int64
负债率     150000 non-null float64
月收入     150000 non-null float64
家属数量    146076 non-null float64
dtypes: float64(3), int64(3)
memory usage: 6.9 MB
```
可以看到，月收入已经没有缺失值了，可以开始正式的分析了。

因为月收入属于连续值，对于连续值进行分析时，我们一般都会将连续值离散化，就是将连续值进行区间切分，分成若干类别。

```
>>>cut_bins=[0,5000,10000,15000,20000,100000]
>>>income_cut=pd.cut(data["月收入"],cut_bins)
>>>income_cut
[(5000, 10000], (0, 5000], (20000, 100000], (10000, 15000],(15000, 20000]]
Categories (5, interval[int64]): [(0, 5000] < (5000, 10000] < (10000, 15000] < (15000, 20000] < (20000, 100000]]
```

区间切分好以后就可以看每个区间内的坏账率，坏账率又该怎么计算呢？坏账率就是所有借款用户中逾期不还用户的占比。逾期不还的用户的好坏客户字段标记为1，非逾期不还的用户的好坏客户字段标记为0。坏账率就等于好坏客户字段的和(坏账客户数)与好坏客户字段的计数(所有借款用户)的比值。

```
>>>all_income_user = data["好坏客户"].groupby(income_cut).count()
>>>bad_income_user = data["好坏客户"].groupby(income_cut).sum()
>>>bad_rate = bad_income_user/all_income_user
>>>bad_rate 
月收入
(0, 5000]          0.087543
(5000, 10000]      0.058308
(10000, 15000]     0.041964
(15000, 20000]     0.041811
(20000, 100000]    0.053615
Name: 好坏客户, dtype: float64
#绘制收入与坏账率关系图
>>>bad_rate.plot.bar()
```

如下图，当收入在1w以下时，收入越高，坏账率月底，当收入超过1.5w时，坏账率又出现了上涨。所以并不是完全是收入越高，坏账率越低，只是在一定范围内，收入越高坏账率会越低。

![](https://i.loli.net/2018/10/20/5bcb4c7e05704.jpg)

### 14.3.2年龄和坏账率有什么关系
年龄又和坏账率有什么关系呢，是不是年龄越大消费更加理性，对信用越看重，坏账率越低呢？

年龄也是连续值，也是同样的处理方式，连续值离散化，代码如下：

```
>>>age_cut=pd.cut(data["年龄"],6)
>>>all_age_user = data["好坏客户"].groupby(age_cut).count()
>>>bad_age_user = data["好坏客户"].groupby(age_cut).sum()
>>>bad_rate = bad_age_user/all_age_user
年龄
(-0.109, 18.167]    0.000000
(18.167, 36.333]    0.110124
(36.333, 54.5]      0.081645
(54.5, 72.667]      0.041719
(72.667, 90.833]    0.021585
(90.833, 109.0]     0.022495
Name: 好坏客户, dtype: float64
#绘制年龄与坏账率关系
>>>bad_rate.plot.bar()
```
如下图，18岁以下人的坏账率为0，18-36年龄段的人坏账率最高，超过36岁以后，随着年龄的增加，坏账率呈下降趋势。

![](https://i.loli.net/2018/10/20/5bcb4b6e36321.jpg)

### 14.3.3家庭人口数量和坏账率有什么关系
家庭人口数量又和坏账率有和关系呢？是家庭人口数量越多，负担越大，坏账率越高？还是家庭人口数量越多，劳动力越多，坏账率越低呢？我们具体看一下家庭人口数量和坏账率的关系。

虽然人口数量也是连续值，但是因为数值不是很大，所以我们就当作离散值进行处理，不进行区间切分。

```
>>>all_age_user = data.groupby("家属数量")["好坏客户"].count()
>>>bad_age_user = data.groupby("家属数量")["好坏客户"].sum()
>>>bad_rate = bad_age_user/all_age_user
家属数量
0.0     0.058629
1.0     0.073529
2.0     0.081139
3.0     0.088263
4.0     0.103774
5.0     0.091153
6.0     0.151899
7.0     0.098039
8.0     0.083333
9.0     0.000000
10.0    0.000000
13.0    0.000000
20.0    0.000000
Name: 好坏客户, dtype: float64
#绘制家属数量与坏账率关系
>>>bad_rate.plot.bar()
```

如下图，看来我们的第一个猜想是对的，家属数量越多，负担越大，坏账率越高，当家属数量大于8人时，坏账率变为0，正常家庭人口数量不会有这么多人，这部分数据可以当作异常值对待，删除不看即可。

![](https://i.loli.net/2018/10/20/5bcb4bb6d24a4.jpg)

# 第十五章:Numpy补充
pandas和numpy两个包是有先后的历史由来的。python被发明出来后，人们就产生了对数值计算的需求，就是高数里面的各种矩阵运算。所以，Numpy就应运而生了。它里面包含了各种类型的数组，可以用来计算数学里面的矩阵运算。
但是，在实际工作中，我们的很多数据都是存放在数据库或者本地的表格中如excel类型的文件。这样的背景，就很需要python能处理表格型数据格式，而不是矩阵。这样，人们又以Numpy为基础开发了Pandas，不仅可以使得pandas能和其他模块相互兼容，也能借助Numpy模块在计算方面性能高的优势。

## 15.1numpy介绍
numpy是针对多维数组(ndarray)的一个科学计算（就是各种运算）包，这个包封装了多个可以用于数组间计算的函数，可以供你直接调用。

数组是相同数据类型的元素按一定顺序排列的组合，这里需要注意的是必须是相同的数据类型。比如全是整数或全是字符串或是其他。

```
array([1, 2, 3, 4, 5, 6])#数值型数组
array(['a', 'b', 'c', 'd', 'e', 'f'], dtype='<U1')#字符型数组
```
## 15.2numpy数组生成
要使用numpy这个包，我们首先需要先有符合numpy这个包的数据，不同的包需要的数据结构是不一样的，比如Pandas包需要的是DataFrame和Series数据结构。

接下来就介绍几种生成数组的方法，在Python中创建数组使用的是array函数，array()函数的参数，即括号里面可以为任何序列型的对象(列表，元组，字符串等)。

在使用numpy这个包的函数或方法之前，首先需要将这个包加载进来：

```
import numpy as np
```
np同样是作为numpy的别名，看到np就代表是numpy库,在一段程序中只需要加载导入进来一次就可以，下面涉及到numpy中的方法，我们都假设numpy库均已加载完成。

### 15.2.1生成一般数组

**给array传入一个列表**

直接将数据以列表的形式作为一个参数传给array()函数：
```
>>>arr = np.array([2,4,6,8])
>>>arr
array([2, 4, 6, 8])
```

**给array传入一个元组**

直接将数据以元组的形式作为一个参数传给array()函数：

```
>>>arr = np.array((2,4,6,8))
>>>arr
array((2, 4, 6, 8))
```

**给array传入一个嵌套列表**

直接将数据以嵌套列表的形式作为一个参数传给array()函数，这个时候会生成一个多维数组：

```
>>>arr = np.array([[1,2,3],[4,5,6]])
>>>arr
array([[1, 2, 3],
       [4, 5, 6]])
```

### 15.2.2生成特殊类型数组

**生成固定范围数组**

生成固定范围的随机数组，需要用到arange()函数：

```
np.arange(start,stop,step)
```

上式代码表示生成一个以start开始(包括start这个值)，stop结束(不包括stop这个值)，step为步长(步长就是数与数之间的间隔)的一个随机序列，具体实例如下：

```
#生成一个以1为开始，15为结束，3为步长的随机序列
>>>np.arange(1,15,3)
array([ 1,  4,  7, 10, 13])
```

当step参数省略不写时，步长默认为1：
```
#生成一个以1开始15为结束，步长默认的随机序列
>>>np.arange(1,15)
array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])
```

当start参数省略不写时，默认从0开始：
```
#生成一个以15为结束，步长默认为1的随机序列
>>>np.arange(15)
array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])

```

**生成指定形状的全为0的数组**

生成指定形状全为0的数组，需要用到zeros()函数。

当只给zeros()函数传入一个具体的值时，会生成相应长度的一个全为0一维数组
```
#生成长度为3的0数组
>>>np.zeros(3)
[0. 0. 0.]
```

当给zeros()函数传入一对值时，会生成相应行列数的全为0的多维数组：
```
#生成2行3列的一个数组
>>>np.zeros((2,3))
[[0. 0. 0.]
 [0. 0. 0.]]
```

**生成指定形状全为1的数组**

生成指定形状全为1的数组，需要用到ones()函数，生成全为1的数组和生成全为0的数组基本是一致的，只不过把全为0数组中的0全部换成1.

当给ones()函数传入一个具体值时，生成相应长度的一个全为
1的一维数组：

```
#生成长度为3的1数组
>>>npp.ones(3)
[ 1.  1.  1.]
```
当给ones()函数传入一对值时，会生成相应行列数全为1的多维数组：

```
>>>np.ones((2,3))
[[ 1.  1.  1.]
 [ 1.  1.  1.]]
```

**生成一个正方形单位矩阵**

单位矩阵就是对角线的元素值全为1，其余位置的元素值全为0，需要用到eye()函数。

eye()函数需要在括号中指明正方向边长：

```
#生成一个3*3的单位矩阵
>>>np.eye(3)
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]]
```

### 15.2.3生成随机数组

随机数组的生成主要用到numpy库中的random模块。

**np.random.rand()**

np.random.rand()方法主要用于生成(0,1)之间的随机数组。

当给rand()函数传入一个具体值时，生成一个相应长度的且值位于(0,1)之间的随机数组：
```
#生成长度为3的位于(0,1)之间的随机数组
>>>np.random.rand(3)
[0.85954324 0.94129099 0.33485322]
```

当给rand()函数传入一对值时，生成相应行列数的多维数组，且数组中的值介于(0,1)之间：

```
#生成2行3列值位于(0,1)之间的数组
>>>np.random.rand(2,3)
[[0.76607317 0.66620877 0.2951136 ]
 [0.96297267 0.25171215 0.99923204]]
```

**np.random.randn()**

np.random.randn()方法用来生成满足正态分布的指定形状数组。

当给randn()函数传入一个具体值时，生成一个相应长度的满足正态分布的随机数组：

```
#生成长度为3的满足正太分布的随机数组
>>>np.random.randn(3)
[-0.30826271  0.38873466 -0.62074553]
```
当给randn()函数传入一对值时，生成相应行列数的多维数组，且数组中的值满足正太分布：

```
#生成2行3列的满足正太分布的随机数组
>>>np.random.randn(2,3)
[[2.22566558 0.97700653 0.18360011]
 [0.53133955 0.41699539 0.23905268]]
```

**np.random.randint()**

np.random.randint()方法与np.arange()方法类似,生成一定范围内的随机数组。

```
np.random.ranint(low,high = None,size = None)
```

表示在左闭右开区间[low,high)上生成数组大小为size的均匀分布的整数值。


```
#在区间[1,5)上生成长度为10的随机数组
>>>np.random.randint(1,5,10)
[3 3 2 2 1 2 4 2 2 3]
```

有的时候high参数为空，这个时候取值区间就变成[0,low)：

```
#在区间[0,5)上生成长度为10的随机数组
>>>np.random.randint(5,10)
[2 0 2 2 3 4 0 3 3 3]
```

参数size可以是一个值，这个时候生成的随机数组是一维的，参数size也可以是一对值，这个时候生成的随机数组就是多维的了：

```
#在区间[0,5)生成2行3列的随机数组
>>>np.random.randint(5,size = (2,3))
[[4 4 3]
 [2 0 0]]
```

**np.random.choice()**

np.random.choice()主要用来从已知数组中随机选取相应大小的数组。

```
np.random.choice(a,size = None,replace = None,p = None)
```

表示从数组a中选取size大小的数组作为一个新的数组，a可以是一个数组，也可以是一个整数，当a是一个数组时表示从该数组中随机采样，当a为一整数时，表示从range(int)中采样

```
#从数组a中选取3个值组成一个新的数组
>>>np.random.ranint(5,3)
[2 1 1]
```

当size是一个具体数值时生成一维数组，当size是一对值时，生成一个指定行列的多维数组：

```
#从数组a中选取2行3列的数值组成一个新的数组
>>>np.random.ranint(5,(2,3))
[[2 4 2]
 [0 3 2]]
```

**np.random.shuffle()**

np.random.shuffle()方法主要是用来将原数组顺序打乱，类似于打扑克牌的洗牌操作。

```
>>>arr = np.arange(10)
>>>arr
[0 1 2 3 4 5 6 7 8 9]#原顺序数组
>>>np.random.shuffle(arr)
[2 7 1 6 3 0 5 8 4 9]#乱序后的数组
```


## 15.3numpy数组基本属性

numpy数组的基本属性主要包括数组的形状、大小、类型和维数。

**数组的形状**

数组的形状就是指这个数组有几行几列数据，直接调用数组的shape方法就可以看到：

```
#3行3列的数组
>>>arr=np.array([[1,2,3],[4,5,6],[7,8,9]])
>>>arr
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])
>>>arr.shape
(3, 3)
```

**数组的大小**

数组的形状是指这个数组中总共有多少个元素，直接调用数组的size方法就可以看到：

```
#arr数组共有9个元素
>>>arr.size
9
```

**数组的类型**

数组的类型指构成这个数组元素都是什么类型，在numpy中主要有如下几种数据类型：


| 类型|说明|
|----|----|
|int|整型数,即整数|
|float|浮点数，即含有小数点|
|object|python对象类型|
|string_ |字符串类型，经常用S表示，S10表示长度为10的字符串|
|unicode_  |固定长度的unicode类型，跟字符串定义方式一样，经常用U表示|

我们要想知道某个数组具体是什么数据类型，只需要调用数组的dtype方法就可以看到：

```
#arr数组的类型为int
>>>arr.dtype
int32
```

**数组的维数**

数组的维数就是指数组是几维空间的，几维空间就对应数组是几维数组，调用数组的ndim方法就可以看到：

```
#arr数组为2维数组
>>>arr.ndim
2
```

```
#arr1数组为1维数组
>>>arr1 = np.array([1,2,3])
>>>arr1
array([1,2,3])
>>>arr1.ndim
1
```

## 15.4数据选取

数据选取就是通过索引的方式把我们想要的某些值从全部数据中抽取出来。

### 15.4.1一维数据选取

一维数据选取，一维你可以理解成数据就是一行或者一列数据，想象一下当我们要从一行或者一列数据中选取我们想要的某些值时我们会怎么选。

先新建一个一维数组供使用：

```
>>>arr = np.arange(10)
>>>arr
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
```

**传入某个位置**

numpy中的位置同样也是从0开始计数的。

```
#获取第4位置的数,即传入3
>>>arr[3]
3
```

有的时候我们想要获取末尾的数值时，可以直接给数组传入-1，表示获取末尾最后一个数值；当给数组传入-2时，表示获取末尾第二个值；也就是数组正序数的话是从0开始，倒序数的话从-1开始数。

```
#获取末尾最后一个数值
>>>arr[-1]
9
```

```
#获取末尾倒数第二个数值
>>>arr[-2]
8
```

**传入某个位置区间**

数组中每个元素都有一个位置，如果你想要获取某些连续位置的元素，就可以将这些元素对应的位置表示成一个区间，只需要写明元素开始位置和结束位置即可，需要注意的是位置默认是一个左闭右开区间，即选取开始位置的元素，但不选取结束位置的元素。

```
#获取位置3到5的值,是不包含位置5的
>>>arr[3:5]
array([3, 4])
```

当你想要选取某个位置之后的所有元素，只需要指明开始位置即可：

```
#获取位置3以后的所有元素
>>>arr[3:]
array([3, 4, 5, 6, 7, 8, 9])
```

同样也可以获取某个位置之前的所有元素，只需指明结束位置即可：

```
#获取位置3之前的所有元素
>>>arr[:3]
array([0, 1, 2])
```

正序位置和倒序位置还可以一起混用：

```
#获取第3位置到倒数第二位置的元素,不包括倒数第二位
>>>arr[3:-2]
array([3, 4, 5, 6, 7])
```

**传入某个条件**

给数组传入某个判断条件，将返回符合该条件的元素。

```
#获取数组中大于3的元素
>>>arr[arr > 3]
array([4, 5, 6, 7, 8, 9])
```

### 15.4.2多维数据选取

多维数据就是指这个数组是多维数组，有多行多列，想象一下我们要从多行多列的数据中选取我们想要的数据，我们会怎么选。

建立一个多维数组供使用：

```
>>>arr = np.array([[1,2,3],[4,5,6],[7,8,9]])
>>>arr
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])
```

**获取某行**

要获取某行数据，直接传入这个行的位置，即第几行即可：

```
#获取第2行数据
>>>arr[1]
array([4, 5, 6])
```

**获取某些行**

要获取某些行数据，直接传入这些行的位置区间即可：

```
#获取第二行到第三行的数据，包括第三行
>>>arr[1:3]
array([[4, 5, 6],
       [7, 8, 9]])
```

同样也可以获取某行之前或之后的所有行数据：

```
#获取第3行之前的所有行数据，不包括第3行
>>>arr[:2]

```

**获取某列**

要获取某列数据，直接在**列位置**处传入这个列的位置，即第几列即可：

```
#获取第2列的数据
>>>arr[:,1]
array([2, 5, 8])
```

逗号之前用来指明行位置，逗号之后用来指明列位置，当逗号之前是一个冒号时，表示获取所有的行。

**获取某些列**

要获取某些列数据，直接在**列位置**传入这些列的位置区间即可：

```
#获取第1到3列的数据，不包括第3列
>>>arr[:,0:2]
array([[1, 2],
       [4, 5],
       [7, 8]])
```


同样也可以获取某列之前或之后的所有列数据：


```
#获取第3列之前的所有列，不包括第3列
>>>arr[:,:2]
array([[1, 2],
       [4, 5],
       [7, 8]])
```

```
#获取第2列之后的所有列，包括第2列
>>>arr[:,1:]
array([[2, 3],
       [5, 6],
       [8, 9]])
```

**行列同时获取**

行列同时获取时，分别在行位置，列位置指明要获取行、列的位置数：

```
#获取第1到2行，第2到3列的数据
>>>arr[0:2,1:3]
array([[2, 3],
       [5, 6]])
```


## 15.5数据预处理
### 15.5.1类型转换

我们在前面说过，不同类型的数值可以做的运算是不一样的，所以我们需要把我们拿到的数据转换成我们想要的数据类型，在numpy数组中转换数据类型用到的方法是astype(),在astype后面的括号中指明要转换成的目标类型即可：

```
>>>arr = np.arange(5)
>>>arr
[0 1 2 3 4]

#数组arr的原数据类型为int32
>>>arr.dtype
int32

#将arr数组从int类型转换为float类型
>>>arr_float = arr.astype(np.float64)
>>>arr_float
array([0., 1., 2., 3., 4.])
>>>arr_float.dtype
dtype('float64')


#将arr数组从int类型转化为str类型
>>>arr_str = arr.astype(np.string_)
>>>arr_str
array([b'0', b'1', b'2', b'3', b'4'], dtype='|S11')
>>>arr_str.dtype
dtype('S11')
```

### 15.5.2缺失值处理

缺失值处理分两步，第一步是先判断是否含有缺失值，将缺失值找出来，第二步是对缺失值进行填充。

第一步找缺失值用到的方法是isnan()，在判断缺失值之前，我们先创建一个含有缺失值的数组，在numpy中缺失值用`np.nan`表示：

```
#创建一个含有缺失值的数组,nan表示缺失值
>>>arr = np.array([1,2,np.nan,4])
>>>arr
array([ 1.,  2., nan,  4.])
```

创建好含有缺失值的数组以后就可以对缺失进行判断,如果某一位置的值为缺失值则该位置返回True，否则返回False,如下：

```
第三位为缺失值
>>>np.isnan(arr)
array([False, False,  True, False])
```

找到缺失值以后就可以对缺失值进行填充，填充方法如下：

```
#用0进行填充
>>>arr[np.isnan(arr)] = 0
array([[1., 2., 0., 4]])
```

### 15.5.3重复值处理

重复值处理比较简单，直接调用unique()方法即可：

```
>>>arr = np.array([1,2,3,2,1])
>>>np.unique(arr)
array([1, 2, 3])
```

## 15.6数组重塑
所谓的数组重塑就是更改数组的形状，比如将原来3行4列的数可以重塑成4行3列的数,在numpy中用reshape方法来实现。
### 15.6.1一维数组重塑
一维数组重塑就是将数组从一行或一列数据重塑为多行多列的数据。

```
#新建一个一维数组
>>>arr = np.arange(8)
>>>arr
array([0, 1, 2, 3, 4, 5, 6, 7])
```

```
#将数组重塑为为2行4列
>>>arr.reshape(2,4)
array([[0, 1, 2, 3],
       [4, 5, 6, 7]])
```

```
#将数组重塑为为4行2列
>>>arr.reshape(4,2)
array([[0, 1],
       [2, 3],
       [4, 5],
       [6, 7]])
```

上面的一维数组既可以转换为2行4列也可以转换为4行2列，是因为不管是2行4列还是4行2列，只要重塑后数组中值的个数等于一维数组中值的个数即可。

### 15.6.2多维数组重塑

```
#新建一个多维数组
>>>arr = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]]) 
>>>arr
array([[ 1,  2,  3,  4],
       [ 5,  6,  7,  8],
       [ 9, 10, 11, 12]])
```

```
#将数组重塑为4行3列
>>>arr.reshape(4,3)
array([[ 1,  2,  3],
       [ 4,  5,  6],
       [ 7,  8,  9],
       [10, 11, 12]])
```

```
#将数组重塑为2行6列
array([[ 1,  2,  3,  4,  5,  6],
       [ 7,  8,  9, 10, 11, 12]])
```

同样可以将3行4列的数组重塑为4行3列或者是2行6列的数组，只要重塑后数组中值的个数等于重塑前数组中值的个数即可。

### 15.6.3数组转置

数组转置就是单纯的将数组的行旋转为列，用到的方法是`.T`，实例如下：

```
>>>arr
array([[ 1,  2,  3,  4],
       [ 5,  6,  7,  8],
       [ 9, 10, 11, 12]])
>>>arr.T
array([[ 1,  5,  9],
       [ 2,  6, 10],
       [ 3,  7, 11],
       [ 4,  8, 12]])
```

## 15.7数组合并
### 15.7.1横向合并
横向合并就是将两个行数相等的数组在行方向进行简单拼接，Numpy数组合并和DataFrame合并不太一样，并不需要公共列，只是将两个数组简单的拼接/堆砌在一起，有concatenate、hstack、column_stack三种方法。

先新建两个数组，用来进行合并：

```
>>>arr1 = np.array([[1,2,3],
                    [4,5,6]])
>>>arr2 = np.array([[7,8,9],
                    [10,11,12]])
```

**concatenate方法**

concatenate方法中将两个待合并的数组以列表的形式传给concatenate，还需要通过设置axis参数来指明在行方向还是在列方向进行合并。

```
>>>np.concatenate([arr1,arr2],axis = 1)
array([[ 1,  2,  3,  7,  8,  9],
       [ 4,  5,  6, 10, 11, 12]])
```
参数`axis = 1`表示数组在行方向上进行合并，参数`axis = 0`表示数组在列方向上进行合并。

**hstack方法**

hstack方法直接将两个待合并数组以元组的形式传给hstack即可，不需要设置参数axis。

```
>>>np.hstack((arr1,arr2))
array([[ 1,  2,  3,  7,  8,  9],
       [ 4,  5,  6, 10, 11, 12]])
```

**column_stack方法**

column_stack方法与hstack方法基本一样，也是将两个待合并的数组以元组的形式传给column_stack即可。

```
>>>np.column_stack((arr1,arr2))
array([[ 1,  2,  3,  7,  8,  9],
       [ 4,  5,  6, 10, 11, 12]])
```

### 15.7.2纵向合并
纵向合并与横向合并类似，横向合并是将两个行数相等的数组在行的方向进行拼接，纵向拼接是将两个列数相等的数组在列的方向进行拼接，同样也有三种方法：concatenate、vstack、row_stack。

**concatenate方法**

使用concatenate方法对数组进行纵向合并时，只需要在横向合并的基础上将参数axis的值从1变成0即可。

```
>>>np.concatenate([arr1,arr2],axis = 0)
array([[ 1,  2,  3],
       [ 4,  5,  6],
       [ 7,  8,  9],
       [10, 11, 12]])
```

**vstack**

vstack是与hstack相对应的方法，同样只需要将待合并的数组以元组的形式传给vstack即可。

```
>>>np.vstack((arr1,arr2))
array([[ 1,  2,  3],
       [ 4,  5,  6],
       [ 7,  8,  9],
       [10, 11, 12]])

```

**row_stack**

row_stack是与column_stack相对应的方法,将两个待合并的数组以元组的形式传给row_stack即可达到数组纵向合并的目的。

```
>>>np.row_stack((arr1,arr2))
array([[ 1,  2,  3],
       [ 4,  5,  6],
       [ 7,  8,  9],
       [10, 11, 12]])
```

## 15.8数据分析
### 15.8.1元素级函数
元素级函数就是针对数组中的每个元素执行相同的函数操作，主要有如下几种：

|函数|说明|
|--|--|
|abs|求取每个元素的绝对值|
|sqrt|求取各元素的平方根|
|square|求取各元素的平方|
|exp|计算各元素的以e为底指数|
|log、log10、log2、log1p|分别计算以e为底,10为底,2为底的对数以及log(1+x)|
|modf|适用于浮点数,将小数和整数部分以独立的数组返回|
|isnan|用来判断是否是"NaN",返回一个布尔值|

```
#新建一个数组
>>>arr = np.arange(4)
>>>arr
array([0, 1, 2, 3])
```

```
#求取各元素的平方
>>>np.square(arr)
array([0, 1, 4, 9], dtype=int32)
```

```
#求取各元素的平方根
>>>np.sqrt(arr)
array([0.        , 1.        , 1.41421356, 1.73205081])
```

### 15.8.2描述统计函数
描述统计函数是对整个numpy数组或某条轴的数据进行统计运算，主要有如下几种函数：

|函数|说明|
|----|----|
|sum|对数组中全部元素或某行/列的元素求和|
|mean|平均值求取|
|std、var|分别为标准差和方差|
|min、max|分别为最小值和最大值|
|argmin、argmax|分别为最大和最小值对应的索引|
|cumsum|所有元素的累计和，结果返回数组的形式|
|cumprod|所有元素的累计积|

**求和**

```
#新建一个数组
>>>arr = np.array([[1,2,3],[4,5,6],[7,8,9]])
>>>arr
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])
```

```
#对整个数组进行求和
>>>arr.sum()
45

#数组中的每一行分别去求和
>>>arr.sum(axis = 1)
array([ 6, 15, 24])


#数组中的每一列分别去求和
>>>arr.sum(axis = 0)
array([12, 15, 18])
```
**求均值**

```
#对整个数组进行求均值
>>>arr.mean()
5.0

#数组中的每一行分别去求均值
>>>arr.mean(axis = 1)
array([2., 5., 8.])

#数组中的每一列分别去求均值
>>>arr.mean(axis = 0)
array([4., 5., 6.])
```

**求最值**

```
#对整个数组进行求最大值
>>>arr.max()
9

#数组中的每一行分别去求最小值
>>>arr.max(axis = 1)
array([3, 6, 9])

#数组中的每一列分别去求最大值
>>>arr.max(axis = 0)
array([7, 8, 9])
```

### 15.8.3条件函数
numpy数组中的条件函数`np.where(condition,x,y)`类似于Excel中`if(condition,"True","False")`函数，如果条件condition为真则返回x，如果条件为假则返回y。

```
#新建一个数组用来存储学生成绩
>>>arr = np.array([56,61,65])
>>>np.where(arr>60,"及格","不及格")#大于60及格，小于60不及格
array(['不及格', '及格', '及格'], dtype='<U3')
```

```
#返回满足条件的值对应的位置
>>>np.where(arr>60)
(array([1, 2], dtype=int64),)
```

### 15.8.4集合关系

每个数组都可以当作一个集合，集合的关系其实就是两个数组之间的关系，主要有包含、交集、并集、差集四种。

```
#新建两个数组
>>>arr1 = np.array([1,2,3,4])
>>>arr2 = np.array([1,2,5])
```

**包含判断**

判断数组arr1中包含数组arr2中的哪些值,如果包含则在对应位置返回True，否则返回False。

```
>>>np.in1d(arr1,arr2)
array([ True,  True, False, False])
```

**交集**

交集就是返回两个数组中的公共部分。

```
>>>np.intersect1d(arr1,arr2)
array([1, 2])
```
                                
**并集**

并集就是返回两个数组中含有的所有数据元素的一个集合。
```
>>>np.union1d(arr1,arr2)
array([1, 2, 3, 4, 5])
```

**差集**


差集就是返回在arr1数组中存在，但是在arr2数组中不存在的元素。
```
>>>np.setdiff1d(arr5_4,arr5_41)
array([3, 4])
```